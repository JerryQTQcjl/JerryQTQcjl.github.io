{"meta":{"title":"Jerry Chan","subtitle":"","description":"","author":"Jerry Chan","url":"http://example.com","root":"/"},"pages":[{"title":"categories","date":"2023-03-25T16:16:19.000Z","updated":"2023-03-25T16:17:15.844Z","comments":false,"path":"categories/index.html","permalink":"http://example.com/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2023-03-25T16:15:37.000Z","updated":"2023-03-25T16:16:54.923Z","comments":false,"path":"tags/index.html","permalink":"http://example.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"让本地配置优先于 apollo 配置","slug":"让本地配置优先于-apollo-配置","date":"2024-09-07T08:55:09.000Z","updated":"2024-09-07T08:58:07.447Z","comments":true,"path":"2024/09/07/让本地配置优先于-apollo-配置/","link":"","permalink":"http://example.com/2024/09/07/%E8%AE%A9%E6%9C%AC%E5%9C%B0%E9%85%8D%E7%BD%AE%E4%BC%98%E5%85%88%E4%BA%8E-apollo-%E9%85%8D%E7%BD%AE/","excerpt":"","text":"为什么需要让本地配置优先于 apollo 呢？当你在本地调试时，开发环境的配置可能无法满足调试条件，例如要升级 mysql，需要在本地调试访问高版本的 mysql，但开发环境的 mysql 版本较低，或者要本地调试访问一个新版的 rpc 接口，或者是要调试访问一个 mock 接口，为了能满足调试条件而不改动开发环境配置影响其他童鞋使用，需要本地配置优先于 apollo 配置。 apollo 配置加载apollo 主要有两类配置源，分别是 ApolloBootstrapPropertySources 和 ApolloPropertySources，ApolloBootstrapPropertySources 主要是提供 bean 工厂初始化时所需的配置参数，例如在 @condition 中使用 apollo 中的配置，ApolloPropertySources 主要供 bean 容器内的 bean 实例使用。 接下先看看 ApolloBootstrapPropertySources 的加载时机 12345678910111213141516171819202122// com.ctrip.framework.apollo.spring.boot.ApolloApplicationContextInitializer@Overridepublic void initialize(ConfigurableApplicationContext context) &#123; ConfigurableEnvironment environment = context.getEnvironment(); // apollo.bootstrap.enabled = true 才支持 String enabled = environment.getProperty(PropertySourcesConstants.APOLLO_BOOTSTRAP_ENABLED, \"false\"); if (!Boolean.valueOf(enabled)) &#123; return; &#125; // 获取需要加载的namespaces String namespaces = environment.getProperty(PropertySourcesConstants.APOLLO_BOOTSTRAP_NAMESPACES, ConfigConsts.NAMESPACE_APPLICATION); List&lt;String&gt; namespaceList = NAMESPACE_SPLITTER.splitToList(namespaces); CompositePropertySource composite = new CompositePropertySource(PropertySourcesConstants.APOLLO_BOOTSTRAP_PROPERTY_SOURCE_NAME); for (String namespace : namespaceList) &#123; Config config = ConfigService.getConfig(namespace); composite.addPropertySource(configPropertySourceFactory.getConfigPropertySource(namespace, config)); &#125; // 添加到environment动态配置源的首位 environment.getPropertySources().addFirst(composite);&#125; ApolloApplicationContextInitializer 实现了 ApplicationContextInitializer，在 SpringApplication#prepareContext 中执行。根据 apollo.bootstrap.enabled 控制是否开启加载，及根据 apollo.bootstrap.namespaces 决定要加载哪些 namespaces。 接下来看看 12345678910111213141516171819202122232425262728293031323334353637383940// com.ctrip.framework.apollo.spring.config.PropertySourcesProcessor@Overridepublic void postProcessBeanFactory(ConfigurableListableBeanFactory beanFactory) throws BeansException &#123; if (INITIALIZED.compareAndSet(false, true)) &#123; // 初始化配置源 initializePropertySources(); // 初始化热更新相关功能 initializeAutoUpdatePropertiesFeature(beanFactory); &#125;&#125;private void initializePropertySources() &#123; if (environment.getPropertySources().contains(PropertySourcesConstants.APOLLO_PROPERTY_SOURCE_NAME)) &#123; //already initialized return; &#125; CompositePropertySource composite = new CompositePropertySource(PropertySourcesConstants.APOLLO_PROPERTY_SOURCE_NAME); //sort by order asc ImmutableSortedSet&lt;Integer&gt; orders = ImmutableSortedSet.copyOf(NAMESPACE_NAMES.keySet()); Iterator&lt;Integer&gt; iterator = orders.iterator(); while (iterator.hasNext()) &#123; int order = iterator.next(); for (String namespace : NAMESPACE_NAMES.get(order)) &#123; Config config = ConfigService.getConfig(namespace); composite.addPropertySource(configPropertySourceFactory.getConfigPropertySource(namespace, config)); &#125; &#125; // add after the bootstrap property source or to the first if (environment.getPropertySources() .contains(PropertySourcesConstants.APOLLO_BOOTSTRAP_PROPERTY_SOURCE_NAME)) &#123; environment.getPropertySources() .addAfter(PropertySourcesConstants.APOLLO_BOOTSTRAP_PROPERTY_SOURCE_NAME, composite); &#125; else &#123; environment.getPropertySources().addFirst(composite); &#125;&#125; PropertySourcesProcessor 继承自 BeanFactoryPostProcessor，会在 bean 工厂初始化完成后，bean 扫描前完成配置源的加载，并且配置源会在 ApolloBootstrapPropertySources 之后。 添加本地配置源知道了 apollo 配置源的加载时机和在环境对象的可变配置源集合的位置之后，就能很容易想到，只要在 bean 初始化前在 ApolloBootstrapPropertySources 前添加本地的配置源即可实现本地配置覆盖 apollo 配置。 1234567891011121314151617181920212223242526272829@Component@ConditionalOnProperty( name = &#123;\"localCoverApollo\"&#125;, havingValue = \"true\")public class ApolloLocalPropertySourcesProcessor implements BeanFactoryPostProcessor, EnvironmentAware &#123; private static final Logger log = LoggerFactory.getLogger(ApolloLocalPropertySourcesProcessor.class); private ConfigurableEnvironment environment; public ApolloLocalPropertySourcesProcessor() &#123; &#125; public void postProcessBeanFactory(ConfigurableListableBeanFactory beanFactory) throws BeansException &#123; try &#123; Properties properties = PropertiesLoaderUtils.loadProperties(new ClassPathResource(\"application.properties\")); PropertiesPropertySource propertySource = new PropertiesPropertySource(\"local\", properties); this.environment.getPropertySources().addFirst(propertySource); log.info(\"本地配置覆盖apollo配置成功，本地配置：&#123;&#125;\", properties); &#125; catch (Exception var4) &#123; Exception e = var4; log.warn(\"本地配置覆盖apollo配置失败\", e); &#125; &#125; public void setEnvironment(Environment environment) &#123; this.environment = (ConfigurableEnvironment)environment; &#125;&#125; 以上是具体实现，总体来说还是非常简单的。如果对上面的代码还有疑问，可以研究一下 Enviroment 获取配置的实现。","categories":[],"tags":[{"name":"apollo","slug":"apollo","permalink":"http://example.com/tags/apollo/"},{"name":"spring","slug":"spring","permalink":"http://example.com/tags/spring/"}]},{"title":"GraalVM + SpringBoot 初探","slug":"GraalVM-SpringBoot-初探","date":"2024-09-03T02:27:04.000Z","updated":"2024-09-03T02:42:00.591Z","comments":true,"path":"2024/09/03/GraalVM-SpringBoot-初探/","link":"","permalink":"http://example.com/2024/09/03/GraalVM-SpringBoot-%E5%88%9D%E6%8E%A2/","excerpt":"","text":"GraalVM 简介 GraalVM compiles your Java applications ahead of time into standalone binaries. These binaries are smaller, start up to 100x faster, provide peak performance with no warmup, and use less memory and CPU than applications running on a Java Virtual Machine (JVM). GraalVM reduces the attack surface of your application. It excludes unused classes, methods, and fields from the application binary. It restricts reflection and other dynamic Java language features to build time only. It does not load any unknown code at run time. Popular microservices frameworks such as Spring Boot, Micronaut, Helidon, and Quarkus, and cloud platforms such as Oracle Cloud Infrastructure, Amazon Web Services, Google Cloud Platform, and Microsoft Azure all support GraalVM. With profile-guided optimization and the G1 (Garbage-First) garbage collector, you can get lower latency and on-par or better peak performance and throughput compared to applications running on a Java Virtual Machine (JVM). You can use the GraalVM JDK just like any other Java Development Kit in your IDE. 以上是来自官网上的介绍，简单来说主要包括几点： GraalVM 支持 AOT（Ahead-Of-Time），提前将 Java 应用编译成可执行的二进制文件，相较于编译成字节码由 JVM 即使编译，拥有更快的速度以及更小的内存。 GraalVM 限制了 Java 的一些动态能力，例如反射、动态代理、java agent等，只允许在构建 Native Image 时使用。（AOT 模式） 优化 JVM 即时编译（JIT），使用 GraalVM 编译器替换 C2 编译器，提升运行时性能。 安装 GraalVM 官网提供了多种下载方式，目前官网只能下载 Java17-22 的版本，如果想要下载其他版本可以到 github 下载。 由于本人使用的是 macos，所以就简单介绍下 macos 下的安装方式，流程还是很简单的，其他操作系统可以进行参考官方文档。 下载对应的 graalvm 版本 解压之后移动到 /Library/Java/JavaVirtualMachines 目录下12tar -xzf graalvm-jdk-&lt;version&gt;_macos-&lt;architecture&gt;.tar.gzsudo mv graalvm-jdk-&lt;version&gt;_macos-&lt;architecture&gt; /Library/Java/JavaVirtualMachines 添加环境变量 如果是从 github 下载的低版本还需要进行一下两个步骤:1234# If you are using macOS Catalina and later you may need to remove the quarantine attribute from the bits before you can use them.sudo xattr -r -d com.apple.quarantine path/to/graalvm/folder/# 官网下载的是默认自带的gu install native-image Java Demo以下是官网提供的和一个纯 Java 应用 Demo: 1234567package com.ylb.explore.graalvm.java;public class HelloWorld &#123; public static void main(String[] args) &#123; System.out.println(\"Hello, Native World!\"); &#125;&#125; 将 Java 代码编译成字节码 1javac HelloWorld.java 将字节码编译成可执行二进制文件 1$JAVA_HOME/bin/native-image com.ylb.explore.graalvm.java.HelloWorld HelloWorld 执行效果 12$ ./HelloWorld Hello, Native World! 总体还是非常简单的，编译时注意一下类路径即可。 SpringBoot Demo接下来看一下一个简单的 SpringBoot 12345678910111213141516171819202122@SpringBootApplicationpublic class DemoApplication &#123; public static void main(String[] args) &#123; long startTime = System.currentTimeMillis(); SpringApplication.run(DemoApplication.class, args); long endTime = System.currentTimeMillis(); System.out.println(\"cost: \" + (endTime - startTime)); &#125;&#125;@RestControllerpublic class IndexController &#123; @RequestMapping(\"/hello\") public String showHelloWorld() &#123; return \"\"\" hello world template \"\"\"; &#125;&#125; 以上代码提供一个简单的 http 接口，接下来配置下 maven 相关插件，如果是使用 gradle 的话可以参考官方文档 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;3.3.3&lt;/version&gt; &lt;/parent&gt; &lt;artifactId&gt;windfall-explore-graalvm-spring-boot&lt;/artifactId&gt; &lt;properties&gt; &lt;java.version&gt;21&lt;/java.version&gt; &lt;maven.compiler.source&gt;21&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;21&lt;/maven.compiler.target&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.main-class&gt;com.ylb.explore.graalvm.spring.boot.DemoApplication&lt;/project.main-class&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-autoconfigure&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.graalvm.buildtools&lt;/groupId&gt; &lt;artifactId&gt;native-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;!-- imageName用于设置生成的二进制文件名称 --&gt; &lt;imageName&gt;$&#123;project.artifactId&#125;&lt;/imageName&gt; &lt;mainClass&gt;$&#123;project.main-class&#125;&lt;/mainClass&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;source&gt;21&lt;/source&gt; &lt;target&gt;21&lt;/target&gt; &lt;compilerArgs&gt;--enable-preview&lt;/compilerArgs&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 直接下执行 maven 插件将代码编译成二进制文件: 1mvn native:compile 这个时候遇到了编译时的第一个坑 这里真正的提示错误没有高亮，反而是下面的 native-image -cp 语句进行了高亮，异步流程就会错过，这里耽搁了我不少时间🌚，解决方案也很简单，在插件中添加配置参数即可 1&lt;mainClass&gt;$&#123;project.main-class&#125;&lt;/mainClass&gt; 添加上 mainClass 后，重新执行编译命令，一切都十分顺利 经过漫长的等待，终于编译成功，那么不出意外，意外马上就来了 1234567891011121314151617181920$ windfall-explore-graalvm-spring-boot . ____ _ __ _ _ /\\\\ / ___'_ __ _ _(_)_ __ __ _ \\ \\ \\ \\( ( )\\___ | '_ | '_| | '_ \\/ _` | \\ \\ \\ \\ \\\\/ ___)| |_)| | | | | || (_| | ) ) ) ) ' |____| .__|_| |_|_| |_\\__, | / / / / =========|_|==============|___/=/_/_/_/ :: Spring Boot :: (v3.3.3)Application run failedorg.springframework.boot.AotInitializerNotFoundException: Startup with AOT mode enabled failed: AOT initializer com.ylb.explore.graalvm.spring.boot.DemoApplication__ApplicationContextInitializer could not be found at org.springframework.boot.SpringApplication.addAotGeneratedInitializerIfNecessary(SpringApplication.java:443) at org.springframework.boot.SpringApplication.prepareContext(SpringApplication.java:400) at org.springframework.boot.SpringApplication.run(SpringApplication.java:334) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1363) at org.springframework.boot.SpringApplication.run(SpringApplication.java:1352) at com.ylb.explore.graalvm.spring.boot.DemoApplication.main(DemoApplication.java:11) at java.base@21.0.4/java.lang.invoke.LambdaForm$DMH/sa346b79c.invokeStaticInit(LambdaForm$DMH) 出现这个错误的主要原因是缺少了 spring boot 的 AOT 元文件信息，需要先通过以下命令编译生成 AOT 元文件 123mvn clean compilmvn spring-boot:process-aotmvn spring-boot:process-aot 接下来再执行 mvn native:compile，坐等二进制文件编译完成即可。 下面对比下使用 jvm 启动和使用二进制文件的耗时: 虽然没有到达了官网所说的 100 倍那么多，但也这个差距相当恐怖了。 以上是在本地编译成可执行文件的方式，spring 官方还提供了直接编译构建 docker 镜像的方式： 1mvn spring-boot:build-image -Pnative 内部是基于 paketobuildpacks/builder-jammy-tiny 和 paketobuildpacks/run-jammy-tiny 构建镜像，底层原理还未了解，但大概率也是作为基础镜像安装相关环境后，编译代码，然后瘦身镜像。这里有一个，请确保 docker 配置了足够多的内存，别问我怎么知道🌚 这里还有一个比较坑的点，使用 GraalVM 编译好的二进制文件，无法直接使用 JDK 提供的一下工具，例如 jstack、jstat 等等，可能对之前习惯使用这些工具的童鞋来说，是难以接受的。 1234567891011$ jps43203 Main18475 Launcher18847 Jps$ ps -ef | grep windfall501 18834 27099 0 10:21AM ttys003 0:00.09 /windfall-common/windfall-explore/windfall-explore-graalvm/windfall-explore-graalvm-spring-boot/target/windfall-explore-graalvm-spring-boot# 甚至会导致进程直接中断，真恐怖$ jstack 19194 19194: No such process 总结 GraalVM 提供了 AOT 编译器，大大提升了代码启动效率，但同时也大大增加了编译时间。 GraalVM 限制了 Java 运行时动态加载的特性，可能很多深度使用 Java 动态加载的应用或者工具并不适用。 GraalVM AOT 编译出来的二进制文件无法使用 JDK 提供的一些监控诊断工具。 参考： https://www.graalvm.org/latest/reference-manual/native-image/ https://graalvm.github.io/native-build-tools/latest/maven-plugin.html https://docs.spring.io/spring-boot/how-to/native-image/developing-your-first-application.html","categories":[],"tags":[]},{"title":"nacos spring 热更新","slug":"nacos-spring-热更新","date":"2024-08-29T16:05:05.000Z","updated":"2024-08-29T16:06:10.264Z","comments":true,"path":"2024/08/30/nacos-spring-热更新/","link":"","permalink":"http://example.com/2024/08/30/nacos-spring-%E7%83%AD%E6%9B%B4%E6%96%B0/","excerpt":"","text":"前言nacos 热更新主要分为全局环境变量热更新和局部 Bean 字段热更新，分别由 @NacosPropertySource 和 @NacosValue 的 autoRefreshed 字段控制，接下来分别看看原理。 全局环境变量热更新全局环境变量热更新由 @NacosPropertySource 的 autoRefreshed 字段控制，接下来看看源码。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950// com.alibaba.nacos.spring.core.env.NacosPropertySourcePostProcessor#doProcessPropertySourceprotected void doProcessPropertySource(String beanName, BeanDefinition beanDefinition) &#123; // 根据注解或者xml配置解析bean对象中配置的配置源 List&lt;NacosPropertySource&gt; nacosPropertySources = buildNacosPropertySources( beanName, beanDefinition); // Add Orderly for (NacosPropertySource nacosPropertySource : nacosPropertySources) &#123; // 将配置源添加到环境对象中 addNacosPropertySource(nacosPropertySource); // 将NacosPropertySource注解中的非空字符串属性和全局配置合并返回 Properties properties = configServiceBeanBuilder .resolveProperties(nacosPropertySource.getAttributesMetadata()); // 添加配置变更监听器 addListenerIfAutoRefreshed(nacosPropertySource, properties, environment); &#125; &#125;// com.alibaba.nacos.spring.core.env.NacosPropertySourcePostProcessor#addListenerIfAutoRefreshedpublic static void addListenerIfAutoRefreshed( final NacosPropertySource nacosPropertySource, final Properties properties, final ConfigurableEnvironment environment) &#123; // 如果NacosPropertySource未开启自动刷新，直接返回 if (!nacosPropertySource.isAutoRefreshed()) &#123; // Disable Auto-Refreshed return; &#125; // 省略部分代码 try &#123; ConfigService configService = nacosServiceFactory.createConfigService(properties); Listener listener = new AbstractListener() &#123; @Override public void receiveConfigInfo(String config) &#123; String name = nacosPropertySource.getName(); // 使用新配置数据构建配置员 NacosPropertySource newNacosPropertySource = new NacosPropertySource( dataId, groupId, name, config, type); // 拷贝旧源配置的元数据 newNacosPropertySource.copy(nacosPropertySource); MutablePropertySources propertySources = environment .getPropertySources(); // 替换环境对象中的源配置 propertySources.replace(name, newNacosPropertySource); &#125; &#125;; // 省略部分代码 configService.addListener(dataId, groupId, listener); &#125; catch (NacosException e) &#123; &#125; &#125; 从上面的代码可以看到，@NacosPropertySource 的 autoRefreshed 字段仅控制环境对象中的配置源更新。 局部 Bean 字段热更新接下来看看局部 Bean 字段更新，局部 Bean 字段更新主要由 @NacosValue 的 autoRefreshed 字段控制，接下来同样看看源码。 12345678910111213141516171819202122232425262728293031323334353637383940414243// com.alibaba.nacos.spring.context.annotation.config.NacosValueAnnotationBeanPostProcessor@Overridepublic Object postProcessBeforeInitialization(Object bean, final String beanName) throws BeansException &#123; doWithFields(bean, beanName); doWithMethods(bean, beanName); return super.postProcessBeforeInitialization(bean, beanName);&#125;// com.alibaba.nacos.spring.context.annotation.config.NacosValueAnnotationBeanPostProcessor#doWithFieldsprivate void doWithFields(final Object bean, final String beanName) &#123; // 解析bean对象中字段的NacosValue注解 ReflectionUtils.doWithFields(bean.getClass(), new ReflectionUtils.FieldCallback() &#123; @Override public void doWith(Field field) throws IllegalArgumentException &#123; NacosValue annotation = getAnnotation(field, NacosValue.class); doWithAnnotation(beanName, bean, annotation, field.getModifiers(), null, field); &#125; &#125;);&#125;// com.alibaba.nacos.spring.context.annotation.config.NacosValueAnnotationBeanPostProcessor#doWithAnnotationprivate void doWithAnnotation(String beanName, Object bean, NacosValue annotation, int modifiers, Method method, Field field) &#123; if (annotation != null) &#123; // 静态字段不处理 if (Modifier.isStatic(modifiers)) &#123; return; &#125; // 开启自动刷新 if (annotation.autoRefreshed()) &#123; // 解析占位符 String placeholder = resolvePlaceholder(annotation.value()); // 将占位符，bean对象，字段信息等缓存在内存中 NacosValueTarget nacosValueTarget = new NacosValueTarget(bean, beanName, method, field, annotation.value()); put2ListMap(placeholderNacosValueTargetMap, placeholder, nacosValueTarget); &#125; &#125; &#125; 从上述代码中可以看到，在 Bean 对象初始化前，会解析对象中添加了 @NacosValue 的字段或者方法，并将相关的字段、对象、注解信息缓存在内存中。接下来看看这些字段是如何实现热更新的。 12345678910111213141516171819202122232425262728293031323334// com.alibaba.nacos.spring.context.annotation.config.NacosValueAnnotationBeanPostProcessor#onApplicationEventpublic void onApplicationEvent(NacosConfigReceivedEvent event) &#123; // In to this event receiver, the environment has been updated the // latest configuration information, pull directly from the environment // fix issue #142 for (Map.Entry&lt;String, List&lt;NacosValueTarget&gt;&gt; entry : placeholderNacosValueTargetMap .entrySet()) &#123; String key = environment.resolvePlaceholders(entry.getKey()); // 从环境变量中取出，因为环境变量更新是在事件发布之前应用事件发布前完成的 // 所以此处获取到的值是已经更新完成之后的数据 String newValue = environment.getProperty(key); if (newValue == null) &#123; continue; &#125; List&lt;NacosValueTarget&gt; beanPropertyList = entry.getValue(); for (NacosValueTarget target : beanPropertyList) &#123; // 比较新旧数据md5校验和 String md5String = MD5Utils.md5Hex(newValue, \"UTF-8\"); boolean isUpdate = !target.lastMD5.equals(md5String); if (isUpdate) &#123; target.updateLastMD5(md5String); Object evaluatedValue = resolveNotifyValue(target.nacosValueExpr, key, newValue); // 更新bean对象字段或方法 if (target.method == null) &#123; setField(target, evaluatedValue); &#125; else &#123; setMethod(target, evaluatedValue); &#125; &#125; &#125; &#125; &#125; 可以看到，当接收到配置变更事件时，会遍历内存中的需要自动更新的 Bean 字段信息，对比 MD5 校验和，如果发现存在变更，则更新 Bean 字段或方法。（此处存在一个疑问，每接收到一个事件都会遍历所有 Bean 字段信息，效率是否较低？） 这里还有一个点需要注意，新的配置数据是直接从环境对象中取出的，这也意味着 @NacosValue 字段的自动更新是会受 @NacosPropertySource 自动更新的影响的。如果 @NacosPropertySource 未开启自动更新，即使 @NacosValue 开启自动更新最终还是无法更新。 更新事件接送接下来再来验证一下上面所说的，全局环境变量的更新是局部 Bean 字段更新之前完成的。 123456789101112131415161718192021222324252627282930// com.alibaba.nacos.client.config.impl.CacheData#safeNotifyListenerprivate void safeNotifyListener(final String dataId, final String group, final String content, final String type, final String md5, final String encryptedDataKey, final ManagerListenerWrap listenerWrap) &#123; NotifyTask job = new NotifyTask() &#123; @Override public void run() &#123; long start = System.currentTimeMillis(); ClassLoader myClassLoader = Thread.currentThread().getContextClassLoader(); ClassLoader appClassLoader = listener.getClass().getClassLoader(); ScheduledFuture&lt;?&gt; timeSchedule = null; try &#123; // 省略部分代码 timeSchedule = getNotifyBlockMonitor().schedule( new LongNotifyHandler(listener.getClass().getSimpleName(), dataId, group, tenant, md5, notifyWarnTimeout, Thread.currentThread()), notifyWarnTimeout, TimeUnit.MILLISECONDS); listenerWrap.inNotifying = true; listener.receiveConfigInfo(contentTmp); // 省略部分代码 &#125; catch (NacosException ex) &#123; &#125; catch (Throwable t) &#123; &#125; finally &#123; &#125; &#125; &#125;; // 省略部分代码&#125; 1234567891011121314151617// com.alibaba.nacos.spring.context.event.config.DelegatingEventPublishingListener#receiveConfigInfopublic void receiveConfigInfo(String content) &#123; onReceived(content); publishEvent(content);&#125;// com.alibaba.nacos.spring.context.event.config.DelegatingEventPublishingListener#publishEventprivate void publishEvent(String content) &#123; NacosConfigReceivedEvent event = new NacosConfigReceivedEvent(configService, dataId, groupId, content, configType); applicationEventPublisher.publishEvent(event);&#125;// com.alibaba.nacos.spring.context.event.config.DelegatingEventPublishingListener#onReceivedprivate void onReceived(String content) &#123; delegate.receiveConfigInfo(content); &#125; 可以看到，先执行 Nacos 原生监听器的 receiveConfigInfo 方法，再发布应用事件。 总结 @NacosPropertySource 的 autoRefreshed 字段控制全局环境变量的更新。 @NacosValue 的 autoRefreshed 字段控制局部 Bean 对象字段更新。 Bean 对象字段更新还是会受到 @NacosPropertySource 的 autoRefreshed 字段的影响，只有 @NacosPropertySource 和 @NacosValue 同时开启自动刷新才能真正自动更新。","categories":[],"tags":[{"name":"nacos","slug":"nacos","permalink":"http://example.com/tags/nacos/"}]},{"title":"一个查询语句在 ShardingJDBC 中都发生了啥","slug":"一个查询语句在-ShardingJDBC-中都发生了啥","date":"2024-08-07T15:44:48.000Z","updated":"2024-08-07T15:58:10.989Z","comments":true,"path":"2024/08/07/一个查询语句在-ShardingJDBC-中都发生了啥/","link":"","permalink":"http://example.com/2024/08/07/%E4%B8%80%E4%B8%AA%E6%9F%A5%E8%AF%A2%E8%AF%AD%E5%8F%A5%E5%9C%A8-ShardingJDBC-%E4%B8%AD%E9%83%BD%E5%8F%91%E7%94%9F%E4%BA%86%E5%95%A5/","excerpt":"","text":"随着业务数据的增长，原本公司中的分库分表方案相对来说不够灵活，所以决定引入业内相对较为成熟的分库分表组件。通过接入成本、性能损耗、社区活跃等多方面考虑，决定引入 SharidngJDBC。但是目前 ShardingJDBC 对部分现有业务无法做到太友好的支持，所以决定基于现有扩展点扩展或者改造源码，为此需要深入阅读 ShardingJDBC 源码。 ShardingJDBC 架构图 以上是从官网拷贝的架构图，图上可以很清晰的看到 SQL 大致流程: 解析引擎进行 SQL 解析，根据数据库类型将 SQL 解析成抽象语法树 路由引擎根据路由规则和抽象语法树，生成路由上下文 改写引擎根据路由上下文和抽象语法树，对 SQL 进行改写，并生成改写上下文 根据路由上下文、改写上下文生成执行上下文 执行引擎执行上下文根据库、连接数等进行分组，并发执行 SQL 合并引擎根据路由规则等对执行结果进行合并等。 以上是 SQL 大致的执行流程，接下来就从源码层面大致看一下具体执行流程。注：本文是基于 5.5.0 的源码。 解析引擎首先看一下 SQL 解析是在哪个阶段执行，再看看具体解析的逻辑。以下是 SQL 解析执行的阶段： 12345678910111213141516171819202122// 预处理语句PreparedStatement preparedStatement = connection.prepareStatement(sql);// org.apache.shardingsphere.driver.jdbc.core.connection.ShardingSphereConnection#prepareStatementpublic PreparedStatement prepareStatement(final String sql) throws SQLException &#123; return new ShardingSpherePreparedStatement(this, sql);&#125;// org.apache.shardingsphere.driver.jdbc.core.statement.ShardingSpherePreparedStatement#ShardingSpherePreparedStatementprivate ShardingSpherePreparedStatement(final ShardingSphereConnection connection, final String sql, final int resultSetType, final int resultSetConcurrency, final int resultSetHoldability, final boolean returnGeneratedKeys, final String[] columns) throws SQLException &#123; // 略... SQLParserRule sqlParserRule = metaDataContexts.getMetaData().getGlobalRuleMetaData().getSingleRule(SQLParserRule.class); // 获取 sql 解析引擎 SQLParserEngine sqlParserEngine = sqlParserRule.getSQLParserEngine(metaDataContexts.getMetaData().getDatabase(connection.getDatabaseName()).getProtocolType()); // 可以通过 SQLParserRuleConfiguration 配置缓存 sqlStatement = sqlParserEngine.parse(this.sql, true); // sqlStatementContext = new SQLBindEngine(metaDataContexts.getMetaData(), connection.getDatabaseName(), hintValueContext).bind(sqlStatement, Collections.emptyList()); // 略...&#125; 从上述可以看到 SQL 解析是在预处理阶段执行的，除了 SQL 解析预处理阶段还初始化了内核处理器，各种执行器等等。 接下来看看 SQL 解析具体是如何执行的，SQL 解析底层依赖于 Antlr4 (不了解的可以看看这边文章 传送门 )： 12345678910111213141516171819202122232425262728293031323334// org.apache.shardingsphere.infra.parser.sql.SQLStatementParserEngine#parsepublic SQLStatement parse(final String sql, final boolean useCache) &#123; // 如果缓存中存在sql对应的 SQLStatement 则直接从缓存中获取，底层使用的 caffeine return useCache ? sqlStatementCache.get(sql) : sqlStatementParserExecutor.parse(sql);&#125;// org.apache.shardingsphere.infra.parser.sql.SQLStatementParserExecutor#parsepublic SQLStatement parse(final String sql) &#123; // 1、基于 Antlr4 语法规则生成抽象语法树 // 2、基于 Antlr4 vistor 生成 SQLStatement return visitorEngine.visit(parserEngine.parse(sql, false));&#125;// org.apache.shardingsphere.sql.parser.api.SQLParserEngine#parsepublic ParseASTNode parse(final String sql, final boolean useCache) &#123; // 通常是优先从缓存中取，如果有则使用缓存，没有则解析 return useCache ? parseTreeCache.get(sql) : sqlParserExecutor.parse(sql);&#125;// org.apache.shardingsphere.sql.parser.core.database.parser.SQLParserExecutor#parsepublic ParseASTNode parse(final String sql) &#123; ParseASTNode result = twoPhaseParse(sql); //... return result;&#125;private ParseASTNode twoPhaseParse(final String sql) &#123; // 基于SPI获取数据库解析器门面，其中包含语法解析器和词法解析器类型 DialectSQLParserFacade sqlParserFacade = DatabaseTypedSPILoader.getService(DialectSQLParserFacade.class, databaseType); // 初始化语法解析器，此处语法解析器是扩展自 Antlr4 生成的代码 SQLParser sqlParser = SQLParserFactory.newInstance(sql, sqlParserFacade.getLexerClass(), sqlParserFacade.getParserClass()); ((Parser) sqlParser).getInterpreter().setPredictionMode(PredictionMode.SLL); return (ParseASTNode) sqlParser.parse();&#125; 以上就是 SQL 解析的具体解析逻辑，底层使用 Antlr4，主要是分为两个阶段： 使用 Antlr4 生成的语法解析器解析 SQL，生成抽象语法树 使用自定义的 Vistor 遍历抽象语法树，并生成对应的 SQLStatement 下面再简单看看 ShardingJDBC 是如何使用 Antlr4 的，具体代码在 shardingsphere-parser 这个模块。 以 MySQL Insert 语句的语法规则为例： 123456789101112131415grammar DMLStatement;import BaseRule;insert : INSERT insertSpecification INTO? tableName partitionNames? (insertValuesClause | setAssignmentsClause | insertSelectClause) onDuplicateKeyClause? ; insertSpecification : (LOW_PRIORITY | DELAYED | HIGH_PRIORITY)? IGNORE? ;insertValuesClause : (LP_ fields? RP_ )? (VALUES | VALUE) (assignmentValues (COMMA_ assignmentValues)* | rowConstructorList) valueReference? ; 12345//org.apache.shardingsphere.sql.parser.mysql.parser.MySQLParser#parsepublic ASTNode parse() &#123; // execute 是根据 Antlr4 生成的语法规则，tokenStream 是词法解析器解析出来的 Token 流 return new ParseASTNode(execute(), (CommonTokenStream) getTokenStream());&#125; 以上是抽象语法树解析相关的内容，可以看到主要就是使用 Antlr4 的语法规则文件生成语法解析相关的代码: execute 是 MySQL 语法解析的总入口，定义在 MySQLStatement.g4 中。 getTokenStream 是获取词法解析器解析出的 TokenStream。 parse 方法实际上做的就是将 Antlr4 解析出的抽象语法树和 TokenStream 封装起来，用于后续 Visitor 遍历使用。 接下来再看看 SQLStatement 生成的过程： 123456789101112131415161718192021222324252627282930313233343536// org.apache.shardingsphere.sql.parser.api.SQLStatementVisitorEngine#visitpublic SQLStatement visit(final ParseASTNode parseASTNode) &#123; // 初始化 visitor, visitor 继承自 Antlr 生成代码 SQLStatementVisitor visitor = SQLStatementVisitorFactory.newInstance(databaseType, SQLVisitorRule.valueOf(parseASTNode.getRootNode().getClass())); // 遍历语法树，生成 SQLStatement ASTNode result = parseASTNode.getRootNode().accept(visitor); appendSQLComments(parseASTNode, result); return (SQLStatement) result;&#125;// org.apache.shardingsphere.sql.parser.mysql.visitor.statement.MySQLStatementVisitor#visitInsertpublic ASTNode visitInsert(final InsertContext ctx) &#123; // TODO :FIXME, since there is no segment for insertValuesClause, InsertStatement is created by sub rule. MySQLInsertStatement result; if (null != ctx.insertValuesClause()) &#123; // 根据 insert value 语法生成 Statemen result = (MySQLInsertStatement) visit(ctx.insertValuesClause()); &#125; else if (null != ctx.insertSelectClause()) &#123; // 根据 insert select 语法生成 Statemen result = (MySQLInsertStatement) visit(ctx.insertSelectClause()); &#125; else // assignment result = new MySQLInsertStatement(); result.setSetAssignment((SetAssignmentSegment) visit(ctx.setAssignmentsClause())); &#125; // 处理 on duplicate if (null != ctx.onDuplicateKeyClause()) &#123; result.setOnDuplicateKeyColumns((OnDuplicateKeyColumnsSegment) visit(ctx.onDuplicateKeyClause())); &#125; // 设置表名 result.setTable((SimpleTableSegment) visit(ctx.tableName())); // 这个暂时不知道作用 result.addParameterMarkerSegments(getParameterMarkerSegments()); return result;&#125; Visitor 的作用主要就是自定义遍历抽象语法树的逻辑，Antlr4 定义的每个语法规则都会生成一个 visit 方法，为了方便理解，可以简单的认为每个节点都会生成一个 visit 方法，visit 方法的入参是抽象语法树的根节点，传入的如果是非叶子节点（子节点）则遍历的是子树。 接下来简单分析一下 visitInsert 方法： visitInsert 是 Insert 语法子树的入口，当执行 parseASTNode.getRootNode().accept(visitor) 会从 visitExecute 开始执行，最终执行到 visitInsert。 如果 insertValuesClause 子树不为空，则遍历 insertValuesClause 子树。 如果 insertSelectClause 子树不为空，则遍历 insertSelectClause 子树。 其他步骤大多类似，最终将遍历各个子树的结果 (Statement) 组装成 Statement 返回。 执行查询接下来看一下执行查询相关逻辑： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273@Overridepublic ResultSet executeQuery() throws SQLException &#123; ResultSet result; try &#123; // 创建查询上下文 QueryContext queryContext = createQueryContext(); // 开启事务 handleAutoCommit(queryContext); // 流量治理相关？暂时不知道作用 trafficInstanceId = getInstanceIdAndSet(queryContext).orElse(null); if (null != trafficInstanceId) &#123; JDBCExecutionUnit executionUnit = createTrafficExecutionUnit(trafficInstanceId, queryContext); return executor.getTrafficExecutor().execute(executionUnit, (statement, sql) -&gt; ((PreparedStatement) statement).executeQuery()); &#125; // todo 联邦查询相关 useFederation = decide(queryContext, metaDataContexts.getMetaData().getDatabase(databaseName), metaDataContexts.getMetaData().getGlobalRuleMetaData()); if (useFederation) &#123; return executeFederationQuery(queryContext); &#125; // 创建执行上下文 executionContext = createExecutionContext(queryContext); // 执行查询 result = doExecuteQuery(executionContext); // CHECKSTYLE:OFF &#125; catch (final RuntimeException ex) &#123; // CHECKSTYLE:ON handleExceptionInTransaction(connection, metaDataContexts); throw SQLExceptionTransformEngine.toSQLException(ex, metaDataContexts.getMetaData().getDatabase(databaseName).getProtocolType()); &#125; return result;&#125;// org.apache.shardingsphere.driver.jdbc.core.statement.ShardingSpherePreparedStatement#createExecutionContextprivate ExecutionContext createExecutionContext(final QueryContext queryContext) &#123; RuleMetaData globalRuleMetaData = metaDataContexts.getMetaData().getGlobalRuleMetaData(); ShardingSphereDatabase currentDatabase = metaDataContexts.getMetaData().getDatabase(databaseName); // sql 审计检查 SQLAuditEngine.audit(queryContext.getSqlStatementContext(), queryContext.getParameters(), globalRuleMetaData, currentDatabase, null, queryContext.getHintValueContext()); // ☆☆☆☆核心☆☆☆☆ 生成执行上下文 ExecutionContext result = kernelProcessor.generateExecutionContext( queryContext, currentDatabase, globalRuleMetaData, metaDataContexts.getMetaData().getProps(), connection.getDatabaseConnectionManager().getConnectionContext()); findGeneratedKey(result).ifPresent(optional -&gt; generatedValues.addAll(optional.getGeneratedValues())); return result;&#125;// org.apache.shardingsphere.driver.jdbc.core.statement.ShardingSpherePreparedStatement#doExecuteQueryprivate ShardingSphereResultSet doExecuteQuery(final ExecutionContext executionContext) throws SQLException &#123; // 执行查询 List&lt;QueryResult&gt; queryResults = executeQuery0(executionContext); // ☆☆☆☆核心☆☆☆☆ 合并结果、加密、脱敏 MergedResult mergedResult = mergeQuery(queryResults, executionContext.getSqlStatementContext()); List&lt;ResultSet&gt; resultSets = getResultSets(); if (null == columnLabelAndIndexMap) &#123; columnLabelAndIndexMap = ShardingSphereResultSetUtils.createColumnLabelAndIndexMap(sqlStatementContext, selectContainsEnhancedTable, resultSets.get(0).getMetaData()); &#125; return new ShardingSphereResultSet(resultSets, mergedResult, this, selectContainsEnhancedTable, executionContext, columnLabelAndIndexMap);&#125;// org.apache.shardingsphere.infra.connection.kernel.KernelProcessor#generateExecutionContextpublic ExecutionContext generateExecutionContext(final QueryContext queryContext, final ShardingSphereDatabase database, final RuleMetaData globalRuleMetaData, final ConfigurationProperties props, final ConnectionContext connectionContext) &#123; // 路由，包括分片、读写分离、数据源匹配等等 // 根据查询上下文、数据库对象、全局规则元数据等参数进行路由，得到路由上下文 RouteContext routeContext = route(queryContext, database, globalRuleMetaData, props, connectionContext); // 根据路由结果改写sql // 根据路由上下文和其他参数，对查询语句进行改写，得到改写结果 SQLRewriteResult rewriteResult = rewrite(queryContext, database, globalRuleMetaData, props, routeContext, connectionContext); // 根据查询上下文、数据库对象、路由上下文、改写结果等信息创建执行上下文 ExecutionContext result = createExecutionContext(queryContext, database, routeContext, rewriteResult); logSQL(queryContext, props, result); return result;&#125; 执行查询主要的逻辑包括执行上下文的创建，以及具体执行查询逻辑。其中联邦查询逻辑由于是实验特性，之后再详看。 执行上下文创建主要包括 SQL 审计、分片路由（分库分表、读写分离、影子库）、SQL 改写（分库分表改写、数据加密） 具体执行逻辑主要包括执行上下文分组、根据分组并发执行、查询结果合并（分片结果合并、分页结果合并、数据脱敏、数据加密） SQL 审计引擎1234567891011121314151617@NoArgsConstructor(access = AccessLevel.PRIVATE)public final class SQLAuditEngine &#123; @SuppressWarnings(&#123;\"rawtypes\", \"unchecked\"&#125;) public static void audit(final SQLStatementContext sqlStatementContext, final List&lt;Object&gt; params, final RuleMetaData globalRuleMetaData, final ShardingSphereDatabase database, final Grantee grantee, final HintValueContext hintValueContext) &#123; Collection&lt;ShardingSphereRule&gt; rules = new LinkedList&lt;&gt;(globalRuleMetaData.getRules()); if (null != database) &#123; rules.addAll(database.getRuleMetaData().getRules()); &#125; // 根据分片规则获取对应的审计规则 for (Entry&lt;ShardingSphereRule, SQLAuditor&gt; entry : OrderedSPILoader.getServices(SQLAuditor.class, rules).entrySet()) &#123; entry.getValue().audit(sqlStatementContext, params, grantee, globalRuleMetaData, database, entry.getKey(), hintValueContext); &#125; &#125;&#125; 审计规则比较简单，主要就是基于 SPI 获取规则对应的审计规则，例如默认的分片审计规则不允许 SQL 中没有分片条件。 路由引擎1234567891011121314151617181920212223// org.apache.shardingsphere.infra.route.engine.impl.PartialSQLRouteExecutor#routepublic RouteContext route(final ConnectionContext connectionContext, final QueryContext queryContext, final RuleMetaData globalRuleMetaData, final ShardingSphereDatabase database) &#123; RouteContext result = new RouteContext(); // 强制路由库 Optional&lt;String&gt; dataSourceName = findDataSourceByHint(queryContext.getHintValueContext(), database.getResourceMetaData().getStorageUnits()); if (dataSourceName.isPresent()) &#123; result.getRouteUnits().add(new RouteUnit(new RouteMapper(dataSourceName.get(), dataSourceName.get()), Collections.emptyList())); return result; &#125; // 装饰器装饰路由上下文，这里的 routers 根据配置的规则而确定，例如 shardingRule，readWriteSplitRule 都会有对应的 routers for (Entry&lt;ShardingSphereRule, SQLRouter&gt; entry : routers.entrySet()) &#123; if (result.getRouteUnits().isEmpty()) &#123; result = entry.getValue().createRouteContext(queryContext, globalRuleMetaData, database, entry.getKey(), props, connectionContext); &#125; else &#123; entry.getValue().decorateRouteContext(result, queryContext, database, entry.getKey(), props, connectionContext); &#125; &#125; if (result.getRouteUnits().isEmpty() &amp;&amp; 1 == database.getResourceMetaData().getStorageUnits().size()) &#123; String singleDataSourceName = database.getResourceMetaData().getStorageUnits().keySet().iterator().next(); result.getRouteUnits().add(new RouteUnit(new RouteMapper(singleDataSourceName, singleDataSourceName), Collections.emptyList())); &#125; return result;&#125; 简单分析下上面的代码： 如果是强制路由数据库，则直接返回。 根据规则获取 SQLRouter，SQLRouter 由 SPI 加载，其中包括单表、分库分表、广播、读写分离影子库等多种 SQLRouter。 SQLRouter 采用装饰器模式，SQLRouter 中定义了优先级，优先级最高的 SQLRouter 创建路由上下文，之后的 SQLRouter 负责装饰路由上下文。 接下来看一下分库分表和读写分离，其他的感兴趣的可以自行看看源码，首先看一下分库分表： 12345678910111213141516171819202122// org.apache.shardingsphere.sharding.route.engine.ShardingSQLRouter#createRouteContext0private RouteContext createRouteContext0(final QueryContext queryContext, final RuleMetaData globalRuleMetaData, final ShardingSphereDatabase database, final ShardingRule rule, final ConfigurationProperties props, final ConnectionContext connectionContext) &#123; // 获取查询上下文中的 sql 语句 SQLStatement sqlStatement = queryContext.getSqlStatementContext().getSqlStatement(); // 解析分片条件 ShardingConditions shardingConditions = createShardingConditions(queryContext, globalRuleMetaData, database, rule); // todo 校验 sql 语句 Optional&lt;ShardingStatementValidator&gt; validator = ShardingStatementValidatorFactory.newInstance(sqlStatement, shardingConditions, globalRuleMetaData); validator.ifPresent(optional -&gt; optional.preValidate(rule, queryContext.getSqlStatementContext(), queryContext.getParameters(), database, props)); // 包含子查询需要合并分片条件 if (sqlStatement instanceof DMLStatement &amp;&amp; shardingConditions.isNeedMerge()) &#123; // 合并查询条件 shardingConditions.merge(); &#125; // 根据sql语句类型，路由规则等获取分片引擎，并分片 RouteContext result = ShardingRouteEngineFactory.newInstance(rule, database, queryContext, shardingConditions, props, connectionContext, globalRuleMetaData) .route(rule); // todo 后置校验 validator.ifPresent(optional -&gt; optional.postValidate(rule, queryContext.getSqlStatementContext(), queryContext.getHintValueContext(), queryContext.getParameters(), database, props, result)); return result;&#125; 以上是 ShardingSQLRouter 创建路由上下文的逻辑，主要包括： 根据分片规则解析分表条件，包括分片表、分片字段、字段值。 SQL 语句校验。 根据分片规则创建对应的分片路由引擎，并创建路由上下文。 下面看看最简单的分片规则路由引擎 (ShardingStandardRoutingEngine) 是怎么实现的： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091// org.apache.shardingsphere.sharding.route.engine.type.standard.ShardingStandardRoutingEngine#routepublic RouteContext route(final ShardingRule shardingRule) &#123; RouteContext result = new RouteContext(); // ☆☆☆☆核心☆☆☆☆ 根据规则，获取数据节点 Collection&lt;DataNode&gt; dataNodes = getDataNodes(shardingRule, shardingRule.getShardingTable(logicTableName)); result.getOriginalDataNodes().addAll(originalDataNodes); for (DataNode each : dataNodes) &#123; // 以路由单位进行封装，封装逻辑库与实际库映射，逻辑表与实际表映射 result.getRouteUnits().add( new RouteUnit(new RouteMapper(each.getDataSourceName(), each.getDataSourceName()), Collections.singleton(new RouteMapper(logicTableName, each.getTableName())))); &#125; return result;&#125;// org.apache.shardingsphere.sharding.route.engine.type.standard.ShardingStandardRoutingEngine#getDataNodesprivate Collection&lt;DataNode&gt; getDataNodes(final ShardingRule shardingRule, final ShardingTable shardingTable) &#123; // 根据规则获取数据库分片策略 ShardingStrategy databaseShardingStrategy = createShardingStrategy(shardingRule.getDatabaseShardingStrategyConfiguration(shardingTable), shardingRule.getShardingAlgorithms(), shardingRule.getDefaultShardingColumn()); // 根据规则获取表分片策略 ShardingStrategy tableShardingStrategy = createShardingStrategy(shardingRule.getTableShardingStrategyConfiguration(shardingTable), shardingRule.getShardingAlgorithms(), shardingRule.getDefaultShardingColumn()); // 强制路由 if (isRoutingByHint(shardingRule, shardingTable)) &#123; return routeByHint(shardingTable, databaseShardingStrategy, tableShardingStrategy); &#125; // 条件路由 if (isRoutingByShardingConditions(shardingRule, shardingTable)) &#123; return routeByShardingConditions(shardingRule, shardingTable, databaseShardingStrategy, tableShardingStrategy); &#125; // 混合强制路由和条件路由，库和表分片其中一个是强制路由 return routeByMixedConditions(shardingRule, shardingTable, databaseShardingStrategy, tableShardingStrategy);&#125;// org.apache.shardingsphere.sharding.route.engine.type.standard.ShardingStandardRoutingEngine#routeByShardingConditionsWithConditionprivate Collection&lt;DataNode&gt; routeByShardingConditionsWithCondition(final ShardingRule shardingRule, final ShardingTable shardingTable, final ShardingStrategy databaseShardingStrategy, final ShardingStrategy tableShardingStrategy) &#123; Collection&lt;DataNode&gt; result = new LinkedList&lt;&gt;(); // 根据分片条件路由，获取数据节点 for (ShardingCondition each : shardingConditions.getConditions()) &#123; Collection&lt;DataNode&gt; dataNodes = route0(shardingTable, databaseShardingStrategy, getShardingValuesFromShardingConditions(shardingRule, databaseShardingStrategy.getShardingColumns(), each), tableShardingStrategy, getShardingValuesFromShardingConditions(shardingRule, tableShardingStrategy.getShardingColumns(), each)); result.addAll(dataNodes); originalDataNodes.add(dataNodes); &#125; return result;&#125;// org.apache.shardingsphere.sharding.route.engine.type.standard.ShardingStandardRoutingEngine#route0private Collection&lt;DataNode&gt; route0(final ShardingTable shardingTable, final ShardingStrategy databaseShardingStrategy, final List&lt;ShardingConditionValue&gt; databaseShardingValues, final ShardingStrategy tableShardingStrategy, final List&lt;ShardingConditionValue&gt; tableShardingValues) &#123; // 路由到对应数据库 Collection&lt;String&gt; routedDataSources = routeDataSources(shardingTable, databaseShardingStrategy, databaseShardingValues); Collection&lt;DataNode&gt; result = new LinkedList&lt;&gt;(); // 路由到对应表 for (String each : routedDataSources) &#123; result.addAll(routeTables(shardingTable, each, tableShardingStrategy, tableShardingValues)); &#125; return result;&#125;// org.apache.shardingsphere.sharding.route.strategy.type.standard.StandardShardingStrategy#doShardingpublic Collection&lt;String&gt; doSharding(final Collection&lt;String&gt; availableTargetNames, final Collection&lt;ShardingConditionValue&gt; shardingConditionValues, final DataNodeInfo dataNodeInfo, final ConfigurationProperties props) &#123; ShardingConditionValue shardingConditionValue = shardingConditionValues.iterator().next(); // 根据分片列是精确查询还是范围查询调用对应的处理方法 Collection&lt;String&gt; shardingResult = shardingConditionValue instanceof ListShardingConditionValue ? doSharding(availableTargetNames, (ListShardingConditionValue) shardingConditionValue, dataNodeInfo) : doSharding(availableTargetNames, (RangeShardingConditionValue) shardingConditionValue, dataNodeInfo); Collection&lt;String&gt; result = new TreeSet&lt;&gt;(String.CASE_INSENSITIVE_ORDER); result.addAll(shardingResult); return result;&#125;// org.apache.shardingsphere.sharding.route.strategy.type.standard.StandardShardingStrategy#doShardingprivate Collection&lt;String&gt; doSharding(final Collection&lt;String&gt; availableTargetNames, final ListShardingConditionValue&lt;?&gt; shardingValue, final DataNodeInfo dataNodeInfo) &#123; Collection&lt;String&gt; result = new LinkedList&lt;&gt;(); for (Object each : shardingValue.getValues()) &#123; // 这里就是我们指定的或者自定义的分片算法 String target = shardingAlgorithm.doSharding(availableTargetNames, new PreciseShardingValue(shardingValue.getTableName(), shardingValue.getColumnName(), dataNodeInfo, each)); if (null != target &amp;&amp; availableTargetNames.contains(target)) &#123; result.add(target); &#125; else if (null != target &amp;&amp; !availableTargetNames.contains(target)) &#123; throw new ShardingRouteAlgorithmException(target, availableTargetNames); &#125; &#125; return result;&#125; 接下来简单分析一下，上述代码是以分片条件进行路由： 路由上下文主要是由一组路由单元组成，路由单元中主要包括库映射和表映射。 路由主要包括库路由和表路由，其中包括强制路由、分片路由、混合强制路由（库强制标条件或者库条件表强制）。 路由的可用数据节点 (DataNodes) 是根据表分片规则的 AcutalDataNode 解析的。 根据我们分片规则指定的分片算法进行路由，路由主要包括等值条件路由和范围条件路由。 如果 SQL 没有分片条件，则进行全库表路由。 接下来看看读写分离的实现： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253// org.apache.shardingsphere.readwritesplitting.route.ReadwriteSplittingSQLRouter#createRouteContext@Overridepublic RouteContext createRouteContext(final QueryContext queryContext, final RuleMetaData globalRuleMetaData, final ShardingSphereDatabase database, final ReadwriteSplittingRule rule, final ConfigurationProperties props, final ConnectionContext connectionContext) &#123; // ReadwriteSplittingSQLRouter在所有SQLRouter中排最后一位，如果是创建路由上下文则说明当前SQL未匹配其他路由条件 RouteContext result = new RouteContext(); ReadwriteSplittingDataSourceRule singleDataSourceRule = rule.getSingleDataSourceRule(); // 直接使用ReadwriteSplittingDataSourceRouter来进行路由 String dataSourceName = new ReadwriteSplittingDataSourceRouter(singleDataSourceRule, connectionContext).route(queryContext.getSqlStatementContext(), queryContext.getHintValueContext()); result.getRouteUnits().add(new RouteUnit(new RouteMapper(singleDataSourceRule.getName(), dataSourceName), Collections.emptyList())); return result;&#125;// org.apache.shardingsphere.readwritesplitting.route.ReadwriteSplittingSQLRouter#decorateRouteContext@Overridepublic void decorateRouteContext(final RouteContext routeContext, final QueryContext queryContext, final ShardingSphereDatabase database, final ReadwriteSplittingRule rule, final ConfigurationProperties props, final ConnectionContext connectionContext) &#123; Collection&lt;RouteUnit&gt; toBeRemoved = new LinkedList&lt;&gt;(); Collection&lt;RouteUnit&gt; toBeAdded = new LinkedList&lt;&gt;(); for (RouteUnit each : routeContext.getRouteUnits()) &#123; // 获取逻辑库对应的读写分离规则，如果逻辑库存在对应规则，并且路由单元的实际库等于读写分离规则名 String dataSourceName = each.getDataSourceMapper().getLogicName(); Optional&lt;ReadwriteSplittingDataSourceRule&gt; dataSourceRule = rule.findDataSourceRule(dataSourceName); if (dataSourceRule.isPresent() &amp;&amp; dataSourceRule.get().getName().equalsIgnoreCase(each.getDataSourceMapper().getActualName())) &#123; toBeRemoved.add(each); // 重新构建路由单元 String actualDataSourceName = new ReadwriteSplittingDataSourceRouter(dataSourceRule.get(), connectionContext).route(queryContext.getSqlStatementContext(), queryContext.getHintValueContext()); toBeAdded.add(new RouteUnit(new RouteMapper(each.getDataSourceMapper().getLogicName(), actualDataSourceName), each.getTableMappers())); &#125; &#125; routeContext.getRouteUnits().removeAll(toBeRemoved); routeContext.getRouteUnits().addAll(toBeAdded);&#125;// org.apache.shardingsphere.readwritesplitting.route.ReadwriteSplittingDataSourceRouter#routepublic String route(final SQLStatementContext sqlStatementContext, final HintValueContext hintValueContext) &#123; for (QualifiedReadwriteSplittingDataSourceRouter each : getQualifiedRouters(connectionContext)) &#123; // 1、写操作、上锁、强制写 2、事务 if (each.isQualified(sqlStatementContext, rule, hintValueContext)) &#123; return each.route(rule); &#125; &#125; // 负载均衡到从库（过滤禁用从库） return new StandardReadwriteSplittingDataSourceRouter().route(rule);&#125;// org.apache.shardingsphere.readwritesplitting.route.ReadwriteSplittingDataSourceRouter#getQualifiedRoutersprivate Collection&lt;QualifiedReadwriteSplittingDataSourceRouter&gt; getQualifiedRouters(final ConnectionContext connectionContext) &#123; // 1、QualifiedReadwriteSplittingPrimaryDataSourceRouter 写操作、上锁、强制路由路由主库 // 2、QualifiedReadwriteSplittingTransactionalDataSourceRouter 事务默认路由主库，FIXED、DYNAMIC策略读从库(过滤禁用的从库) return Arrays.asList(new QualifiedReadwriteSplittingPrimaryDataSourceRouter(), new QualifiedReadwriteSplittingTransactionalDataSourceRouter(connectionContext));&#125; 读写分离路由器主要分为创建路由单元和装饰路由单元 由于读写分离路由器在所有路由器中排在最后一位，如果是创建路由单元说明其他路由规则都没有匹配到，此时直接使用 ReadwriteSplittingDataSourceRouter 进行路由 如果是装饰路由上下文，则遍历路由单元，如果匹配上读写分离规则则重新使用 ReadwriteSplittingDataSourceRouter 进行路由后覆盖原本的路由单元 ReadwriteSplittingDataSourceRouter 主要是根据以下两个条件判断是否读主库 写操作、上锁、强制路由路由主库 事务默认路由主库，FIXED、DYNAMIC策略读从库(过滤禁用的从库) 其他情况都是负载均衡到从库（具体负载均衡规则是我们自己指定的） 改写引擎12345678910// org.apache.shardingsphere.infra.rewrite.SQLRewriteEntry#rewritepublic SQLRewriteResult rewrite(final QueryContext queryContext, final RouteContext routeContext, final ConnectionContext connectionContext) &#123; // ☆☆☆☆核心☆☆☆☆ 创建sql改写上下文，包括sqlToken的生成 SQLRewriteContext sqlRewriteContext = createSQLRewriteContext(queryContext, routeContext, connectionContext); SQLTranslatorRule rule = globalRuleMetaData.getSingleRule(SQLTranslatorRule.class); // 改写，根据是否有路由单元选择对应的改写引擎 return routeContext.getRouteUnits().isEmpty() ? new GenericSQLRewriteEngine(rule, database, globalRuleMetaData).rewrite(sqlRewriteContext, queryContext) : new RouteSQLRewriteEngine(rule, database, globalRuleMetaData).rewrite(sqlRewriteContext, routeContext, queryContext);&#125; SQL 改写主要有两个部分组成： SQL 改写上下文的创建，包括 sqlToken 的生成，sqlToken 主要用于改写 SQL。 根据路由上下文和 SQL 改写上下文进行改写。 接下来先看一下 SQL 改写上下文的创建： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273// org.apache.shardingsphere.infra.rewrite.SQLRewriteEntry#createSQLRewriteContextprivate SQLRewriteContext createSQLRewriteContext(final QueryContext queryContext, final RouteContext routeContext, final ConnectionContext connectionContext) &#123; HintValueContext hintValueContext = queryContext.getHintValueContext(); SQLRewriteContext result = new SQLRewriteContext(database, queryContext.getSqlStatementContext(), queryContext.getSql(), queryContext.getParameters(), connectionContext, hintValueContext); // 装饰sql改写上下文 decorate(decorators, result, routeContext, hintValueContext); // 生成 sqlToken，sqlToken 主要是针对sql语句的各个分段进行改写，例如表名、字段、字段值等等 result.generateSQLTokens(); return result;&#125;// org.apache.shardingsphere.infra.rewrite.SQLRewriteEntry#decorateprivate void decorate(final Map&lt;ShardingSphereRule, SQLRewriteContextDecorator&gt; decorators, final SQLRewriteContext sqlRewriteContext, final RouteContext routeContext, final HintValueContext hintValueContext) &#123; // 强制路由可以绕过改写 if (hintValueContext.isSkipSQLRewrite()) &#123; return; &#125; for (Entry&lt;ShardingSphereRule, SQLRewriteContextDecorator&gt; entry : decorators.entrySet()) &#123; // ☆☆☆☆核心☆☆☆☆ 基于装饰器扩展点，可以添加一些自己需要的sqlToken，用于扩展改写sql entry.getValue().decorate(entry.getKey(), props, sqlRewriteContext, routeContext); &#125;&#125;// org.apache.shardingsphere.sharding.rewrite.context.ShardingSQLRewriteContextDecorator#decoratepublic void decorate(final ShardingRule shardingRule, final ConfigurationProperties props, final SQLRewriteContext sqlRewriteContext, final RouteContext routeContext) &#123; SQLStatementContext sqlStatementContext = sqlRewriteContext.getSqlStatementContext(); if (sqlStatementContext instanceof InsertStatementContext &amp;&amp; !containsShardingTable(shardingRule, sqlStatementContext)) &#123; return; &#125; if (!sqlRewriteContext.getParameters().isEmpty()) &#123; Collection&lt;ParameterRewriter&gt; parameterRewriters = new ShardingParameterRewriterBuilder(shardingRule, routeContext, sqlRewriteContext.getDatabase().getSchemas(), sqlStatementContext).getParameterRewriters(); rewriteParameters(sqlRewriteContext, parameterRewriters); &#125; // 添加sqlToken构建器 sqlRewriteContext.addSQLTokenGenerators(new ShardingTokenGenerateBuilder(shardingRule, routeContext, sqlStatementContext).getSQLTokenGenerators());&#125;// org.apache.shardingsphere.sharding.rewrite.token.ShardingTokenGenerateBuilder#getSQLTokenGeneratorspublic Collection&lt;SQLTokenGenerator&gt; getSQLTokenGenerators() &#123; Collection&lt;SQLTokenGenerator&gt; result = new LinkedList&lt;&gt;(); addSQLTokenGenerator(result, new TableTokenGenerator()); addSQLTokenGenerator(result, new DistinctProjectionPrefixTokenGenerator()); addSQLTokenGenerator(result, new ProjectionsTokenGenerator()); addSQLTokenGenerator(result, new OrderByTokenGenerator()); addSQLTokenGenerator(result, new AggregationDistinctTokenGenerator()); addSQLTokenGenerator(result, new IndexTokenGenerator()); addSQLTokenGenerator(result, new ConstraintTokenGenerator()); addSQLTokenGenerator(result, new OffsetTokenGenerator()); addSQLTokenGenerator(result, new RowCountTokenGenerator()); addSQLTokenGenerator(result, new GeneratedKeyInsertColumnTokenGenerator()); addSQLTokenGenerator(result, new GeneratedKeyForUseDefaultInsertColumnsTokenGenerator()); addSQLTokenGenerator(result, new GeneratedKeyAssignmentTokenGenerator()); addSQLTokenGenerator(result, new ShardingInsertValuesTokenGenerator()); addSQLTokenGenerator(result, new GeneratedKeyInsertValuesTokenGenerator()); addSQLTokenGenerator(result, new ShardingRemoveTokenGenerator()); addSQLTokenGenerator(result, new CursorTokenGenerator()); addSQLTokenGenerator(result, new FetchDirectionTokenGenerator()); return result;&#125;// org.apache.shardingsphere.sharding.rewrite.token.generator.impl.TableTokenGenerator#generateSQLTokensprivate Collection&lt;SQLToken&gt; generateSQLTokens(final TableAvailable sqlStatementContext) &#123; Collection&lt;SQLToken&gt; result = new LinkedList&lt;&gt;(); for (SimpleTableSegment each : sqlStatementContext.getAllTables()) &#123; TableNameSegment tableName = each.getTableName(); if (shardingRule.findShardingTable(tableName.getIdentifier().getValue()).isPresent()) &#123; result.add(new TableToken(tableName.getStartIndex(), tableName.getStopIndex(), tableName.getIdentifier(), (SQLStatementContext) sqlStatementContext, shardingRule)); &#125; &#125; return result;&#125; SQL 改写上下文的创建最主要就是创建 sqlToken，其中可以分为几个步骤： 根据规则获取 SQL 改写上下文装饰器，主要包括分片规则和数据加密装饰器。 1decorators = OrderedSPILoader.getServices(SQLRewriteContextDecorator.class, database.getRuleMetaData().getRules()); 装饰器主要作用就是添加 sqlToken 构建器。 统一生成 sqlToken，sqlToken 主要是针对 SQL 语句的各个分段进行改写，例如表名、字段、字段值等等。以 TableToken 为例，TableToken 从 SQL 解析出来的 TableStatement 中获取到表名的起始结束位置，改写时就是利用字符串截取替换起始结束位置之间的字符串。 接下来看一下具体的改写逻辑实现： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071 // org.apache.shardingsphere.infra.rewrite.engine.RouteSQLRewriteEngine#rewrite public RouteSQLRewriteResult rewrite(final SQLRewriteContext sqlRewriteContext, final RouteContext routeContext, final QueryContext queryContext) &#123; Map&lt;RouteUnit, SQLRewriteUnit&gt; sqlRewriteUnits = new LinkedHashMap&lt;&gt;(routeContext.getRouteUnits().size(), 1F); // 根据数据库分组 for (Entry&lt;String, Collection&lt;RouteUnit&gt;&gt; entry : aggregateRouteUnitGroups(routeContext.getRouteUnits()).entrySet()) &#123; Collection&lt;RouteUnit&gt; routeUnits = entry.getValue(); // 同一个库的查询语句，且不包含子查询、关联查询、排序、分页、锁 if (isNeedAggregateRewrite(sqlRewriteContext.getSqlStatementContext(), routeUnits)) &#123; // 用 union all 连接 sql sqlRewriteUnits.put(routeUnits.iterator().next(), createSQLRewriteUnit(sqlRewriteContext, routeContext, routeUnits)); &#125; else &#123; // 改写sql后封装成sql改写单元 addSQLRewriteUnits(sqlRewriteUnits, sqlRewriteContext, routeContext, routeUnits); &#125; &#125; // 翻译SQL，官方暂未提供实现 return new RouteSQLRewriteResult(translate(queryContext, sqlRewriteUnits));&#125;// org.apache.shardingsphere.infra.rewrite.engine.RouteSQLRewriteEngine#createSQLRewriteUnitprivate SQLRewriteUnit createSQLRewriteUnit(final SQLRewriteContext sqlRewriteContext, final RouteContext routeContext, final Collection&lt;RouteUnit&gt; routeUnits) &#123; Collection&lt;String&gt; sql = new LinkedList&lt;&gt;(); List&lt;Object&gt; params = new LinkedList&lt;&gt;(); // 参数是否是$开头 boolean containsDollarMarker = sqlRewriteContext.getSqlStatementContext() instanceof SelectStatementContext &amp;&amp; ((SelectStatementContext) (sqlRewriteContext.getSqlStatementContext())).isContainsDollarParameterMarker(); for (RouteUnit each : routeUnits) &#123; // 移除sql中的;号 sql.add(SQLUtils.trimSemicolon(new RouteSQLBuilder(sqlRewriteContext, each).toSQL())); if (containsDollarMarker &amp;&amp; !params.isEmpty()) &#123; continue; &#125; params.addAll(getParameters(sqlRewriteContext.getParameterBuilder(), routeContext, each)); &#125; // 用 union all 连接 sql return new SQLRewriteUnit(String.join(\" UNION ALL \", sql), params);&#125;// org.apache.shardingsphere.infra.rewrite.engine.RouteSQLRewriteEngine#addSQLRewriteUnitsprivate void addSQLRewriteUnits(final Map&lt;RouteUnit, SQLRewriteUnit&gt; sqlRewriteUnits, final SQLRewriteContext sqlRewriteContext, final RouteContext routeContext, final Collection&lt;RouteUnit&gt; routeUnits) &#123; for (RouteUnit each : routeUnits) &#123; // ☆☆☆☆核心☆☆☆☆ RouteSQLBuilder.toSQL() 改写sql sqlRewriteUnits.put(each, new SQLRewriteUnit(new RouteSQLBuilder(sqlRewriteContext, each).toSQL(), getParameters(sqlRewriteContext.getParameterBuilder(), routeContext, each))); &#125;&#125;// org.apache.shardingsphere.infra.rewrite.sql.impl.AbstractSQLBuilder#toSQLpublic final String toSQL() &#123; if (context.getSqlTokens().isEmpty()) &#123; return context.getSql(); &#125; // 根据sqlToken的startIndex进行排序 Collections.sort(context.getSqlTokens()); // 遍历sqlToken替换和组装sql字符串 StringBuilder result = new StringBuilder(); result.append(context.getSql(), 0, context.getSqlTokens().get(0).getStartIndex()); for (SQLToken each : context.getSqlTokens()) &#123; if (each instanceof ComposableSQLToken) &#123; result.append(getComposableSQLTokenText((ComposableSQLToken) each)); &#125; else if (each instanceof SubstitutableColumnNameToken) &#123; result.append(((SubstitutableColumnNameToken) each).toString(routeUnit)); &#125; else &#123; // sqlToken本身是包含抽象语法树语法节点的数据，所以可以直接进行组装 result.append(getSQLTokenText(each)); &#125; // 组装sqlToken之间的连接符 result.append(getConjunctionText(each)); &#125; return result.toString();&#125; 具体的改写逻辑还是比较简单的，主要就是利用 sqlToken 组装 SQL，因为 sqlToken 本身在生成时就包含语法树的节点数据，所以只需要根据规则进行处理即可，例如分库分表、数据加密。 合并引擎在讲合并引擎之前，先简单看一下具体执行查询的逻辑 12345678910111213141516171819202122232425262728293031323334353637// org.apache.shardingsphere.driver.jdbc.core.statement.ShardingSpherePreparedStatement#executeQuery0private List&lt;QueryResult&gt; executeQuery0(final ExecutionContext executionContext) throws SQLException &#123; // 按每个数据源的连接数分组，一个连接下可以包含一个数据源下的多个sql ExecutionGroupContext&lt;JDBCExecutionUnit&gt; executionGroupContext = createExecutionGroupContext(executionContext); return executor.getRegularExecutor().executeQuery(executionGroupContext, executionContext.getQueryContext(), new PreparedStatementExecuteQueryCallback(metaDataContexts.getMetaData().getDatabase(databaseName).getProtocolType(), metaDataContexts.getMetaData().getDatabase(databaseName).getResourceMetaData(), sqlStatement, SQLExecutorExceptionHandler.isExceptionThrown()));&#125;// org.apache.shardingsphere.infra.executor.sql.prepare.AbstractExecutionPrepareEngine#preparepublic final ExecutionGroupContext&lt;T&gt; prepare(final RouteContext routeContext, final Map&lt;String, Integer&gt; connectionOffsets, final Collection&lt;ExecutionUnit&gt; executionUnits, final ExecutionGroupReportContext reportContext) throws SQLException &#123; Collection&lt;ExecutionGroup&lt;T&gt;&gt; result = new LinkedList&lt;&gt;(); // 按数据原分数 for (Entry&lt;String, List&lt;ExecutionUnit&gt;&gt; entry : aggregateExecutionUnitGroups(executionUnits).entrySet()) &#123; String dataSourceName = entry.getKey(); // 按每个数据源的连接数拆分成多执行单元（sql）集合 List&lt;List&lt;ExecutionUnit&gt;&gt; executionUnitGroups = group(entry.getValue()); ConnectionMode connectionMode = maxConnectionsSizePerQuery &lt; entry.getValue().size() ? ConnectionMode.CONNECTION_STRICTLY : ConnectionMode.MEMORY_STRICTLY; // 按每个数据源的连接数分组，一个连接下可以包含一个数据源下的多个sql result.addAll(group(dataSourceName, connectionOffsets.getOrDefault(dataSourceName, 0), executionUnitGroups, connectionMode)); &#125; // 可扩展的装饰器 return decorate(routeContext, result, reportContext);&#125;// org.apache.shardingsphere.infra.executor.kernel.ExecutorEngine#executepublic &lt;I, O&gt; List&lt;O&gt; execute(final ExecutionGroupContext&lt;I&gt; executionGroupContext, final ExecutorCallback&lt;I, O&gt; firstCallback, final ExecutorCallback&lt;I, O&gt; callback, final boolean serial) throws SQLException &#123; if (executionGroupContext.getInputGroups().isEmpty()) &#123; return Collections.emptyList(); &#125; return serial ? serialExecute(executionGroupContext.getInputGroups().iterator(), executionGroupContext.getReportContext().getProcessId(), firstCallback, callback) : parallelExecute(executionGroupContext.getInputGroups().iterator(), executionGroupContext.getReportContext().getProcessId(), firstCallback, callback);&#125; 执行逻辑主要包括两部分： 根据数据库和单库最大连接数 (maxConnectionsSizePerQuery) 对执行单元进行分组 根据分组后的执行单元并发执行，以求最大的执行效率（分布式事务串行执行） 接下来看看合并引擎相关逻辑： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162// org.apache.shardingsphere.driver.jdbc.core.statement.ShardingSpherePreparedStatement#mergeQueryprivate MergedResult mergeQuery(final List&lt;QueryResult&gt; queryResults, final SQLStatementContext sqlStatementContext) throws SQLException &#123; // 合并引擎，包括分片合并、数据脱敏、数据加密 MergeEngine mergeEngine = new MergeEngine(metaDataContexts.getMetaData().getDatabase(databaseName), metaDataContexts.getMetaData().getProps(), connection.getDatabaseConnectionManager().getConnectionContext()); return mergeEngine.merge(queryResults, sqlStatementContext);&#125;// org.apache.shardingsphere.infra.merge.MergeEngine#mergepublic MergedResult merge(final List&lt;QueryResult&gt; queryResults, final SQLStatementContext sqlStatementContext) throws SQLException &#123; // 分片结果合并 Optional&lt;MergedResult&gt; mergedResult = executeMerge(queryResults, sqlStatementContext); // 结果处理，数据脱敏、数据解密 Optional&lt;MergedResult&gt; result = mergedResult.isPresent() ? Optional.of(decorate(mergedResult.get(), sqlStatementContext)) : decorate(queryResults.get(0), sqlStatementContext); return result.orElseGet(() -&gt; new TransparentMergedResult(queryResults.get(0)));&#125;// org.apache.shardingsphere.infra.merge.MergeEngine#executeMergeprivate Optional&lt;MergedResult&gt; executeMerge(final List&lt;QueryResult&gt; queryResults, final SQLStatementContext sqlStatementContext) throws SQLException &#123; for (Entry&lt;ShardingSphereRule, ResultProcessEngine&gt; entry : engines.entrySet()) &#123; if (entry.getValue() instanceof ResultMergerEngine) &#123; ResultMerger resultMerger = ((ResultMergerEngine) entry.getValue()).newInstance(database.getName(), database.getProtocolType(), entry.getKey(), props, sqlStatementContext); return Optional.of(resultMerger.merge(queryResults, sqlStatementContext, database, connectionContext)); &#125; &#125; return Optional.empty();&#125;// org.apache.shardingsphere.sharding.merge.dql.ShardingDQLResultMerger#buildprivate MergedResult build(final List&lt;QueryResult&gt; queryResults, final SelectStatementContext selectStatementContext, final Map&lt;String, Integer&gt; columnLabelIndexMap, final ShardingSphereDatabase database) throws SQLException &#123; String defaultSchemaName = new DatabaseTypeRegistry(selectStatementContext.getDatabaseType()).getDefaultSchemaName(database.getName()); ShardingSphereSchema schema = selectStatementContext.getTablesContext().getSchemaName() .map(database::getSchema).orElseGet(() -&gt; database.getSchema(defaultSchemaName)); // 分组、字段是聚合函数，例如sum()、min() if (isNeedProcessGroupBy(selectStatementContext)) &#123; return getGroupByMergedResult(queryResults, selectStatementContext, columnLabelIndexMap, schema); &#125; // 去重 distinct if (isNeedProcessDistinctRow(selectStatementContext)) &#123; setGroupByForDistinctRow(selectStatementContext); return getGroupByMergedResult(queryResults, selectStatementContext, columnLabelIndexMap, schema); &#125; // 排序 if (isNeedProcessOrderBy(selectStatementContext)) &#123; return new OrderByStreamMergedResult(queryResults, selectStatementContext, schema); &#125; return new IteratorStreamMergedResult(queryResults);&#125;// org.apache.shardingsphere.infra.merge.MergeEngine#decorateprivate MergedResult decorate(final MergedResult mergedResult, final SQLStatementContext sqlStatementContext) throws SQLException &#123; MergedResult result = null; for (Entry&lt;ShardingSphereRule, ResultProcessEngine&gt; entry : engines.entrySet()) &#123; if (entry.getValue() instanceof ResultDecoratorEngine) &#123; // 获取结果集装饰器 ResultDecorator resultDecorator = getResultDecorator(sqlStatementContext, entry); result = null == result ? resultDecorator.decorate(mergedResult, sqlStatementContext, entry.getKey()) : resultDecorator.decorate(result, sqlStatementContext, entry.getKey()); &#125; &#125; return null == result ? mergedResult : result;&#125; 合并引擎主要分为两个部分： 查询结果合并，包括聚合、排序、去重、分页 查询结果值处理，包括数据脱敏、解密 注意，合并引擎实际只是返回上着做了封装的 MergedResult，具体的合并逻辑实际是在遍历获取结果数据时进行的，下面以排序结果合并为例子，看看合并具体是如何执行的： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990// org.apache.shardingsphere.sharding.merge.dql.orderby.OrderByStreamMergedResultpublic class OrderByStreamMergedResult extends StreamMergedResult &#123; private final Collection&lt;OrderByItem&gt; orderByItems; @Getter(AccessLevel.PROTECTED) private final Queue&lt;OrderByValue&gt; orderByValuesQueue; @Getter(AccessLevel.PROTECTED) private boolean isFirstNext; public OrderByStreamMergedResult(final List&lt;QueryResult&gt; queryResults, final SelectStatementContext selectStatementContext, final ShardingSphereSchema schema) throws SQLException &#123; orderByItems = selectStatementContext.getOrderByContext().getItems(); orderByValuesQueue = new PriorityQueue&lt;&gt;(queryResults.size()); orderResultSetsToQueue(queryResults, selectStatementContext, schema); isFirstNext = true; &#125; private void orderResultSetsToQueue(final List&lt;QueryResult&gt; queryResults, final SelectStatementContext selectStatementContext, final ShardingSphereSchema schema) throws SQLException &#123; for (QueryResult each : queryResults) &#123; OrderByValue orderByValue = new OrderByValue(each, orderByItems, selectStatementContext, schema); if (orderByValue.next()) &#123; orderByValuesQueue.offer(orderByValue); &#125; &#125; setCurrentQueryResult(orderByValuesQueue.isEmpty() ? queryResults.get(0) : orderByValuesQueue.peek().getQueryResult()); &#125; @Override public boolean next() throws SQLException &#123; if (orderByValuesQueue.isEmpty()) &#123; return false; &#125; if (isFirstNext) &#123; isFirstNext = false; return true; &#125; // 取出排序优先队列中的第一个结果集 OrderByValue firstOrderByValue = orderByValuesQueue.poll(); // 如果第一个结果集中存在下一个元素，则将结果集下一个元素中的值复制到OrderByValue中， // 然后重新放回优先队列中，从而保证所有结果集的顺序是正确的 if (firstOrderByValue.next()) &#123; orderByValuesQueue.offer(firstOrderByValue); &#125; // 优先队列为空则说明遍历到最后一个元素 if (orderByValuesQueue.isEmpty()) &#123; return false; &#125; //取当前顺序最前的元素，但不移除元素 setCurrentQueryResult(orderByValuesQueue.peek().getQueryResult()); return true; &#125;&#125;// org.apache.shardingsphere.sharding.merge.dql.orderby.OrderByValuepublic final class OrderByValue implements Comparable&lt;OrderByValue&gt; &#123; public boolean next() throws SQLException &#123; // 移动游标 boolean result = queryResult.next(); // 将当前游标的排序字段值赋值给orderValues orderValues = result ? getOrderValues() : Collections.emptyList(); return result; &#125; private List&lt;Comparable&lt;?&gt;&gt; getOrderValues() throws SQLException &#123; List&lt;Comparable&lt;?&gt;&gt; result = new ArrayList&lt;&gt;(orderByItems.size()); for (OrderByItem each : orderByItems) &#123; Object value = queryResult.getValue(each.getIndex(), Object.class); ShardingSpherePreconditions.checkState(null == value || value instanceof Comparable, () -&gt; new NotImplementComparableValueException(\"Order by\", value)); result.add((Comparable&lt;?&gt;) value); &#125; return result; &#125; @Override public int compareTo(final OrderByValue orderByValue) &#123; int i = 0; // 对比多个游标的当前值 for (OrderByItem each : orderByItems) &#123; int result = CompareUtils.compareTo(orderValues.get(i), orderByValue.orderValues.get(i), each.getSegment().getOrderDirection(), each.getSegment().getNullsOrderType(selectStatementContext.getDatabaseType()), orderValuesCaseSensitive.get(i)); if (0 != result) &#123; return result; &#125; i++; &#125; return 0; &#125;&#125; 简单分析一下排序结果集合并的代码，假设一条查询语句 1select f_id, f_name from t_user order by f_id; 分片路由后需要查询四张表，那么最终就会产生四个结果集，以这个场景为例子看看结果是如何合并的： 将各个结果集封装成 OrderByValue，并将结果集的第一个行数据的排序字段赋值给 OrderByValue，OrderByValue 根据结果集赋值的排序字段对比进行排序。 将封装好的 OrderByValue 放入优先队列中，那么最初就是根绝每个结果集的第一个行数据的排序字段进行排序。 在执行 OrderByStreamMergedResult.next 时，实际上就是将优先队列中的第一个结果集取出并将它的游标移动到下一位，并重新将排序字段赋值给 OrderByValue 后放入优先队列中。 然后再返回优先队列中排在第一位的结果集，但不从队列移除，此时该结果集的游标所处位置表示的就是排序最前的行数据。 反复执行 3、4 步骤，直到遍历完所有结果集下的所有行数据，一次保证所有结果集数据的顺序。 以上就是排序结果集合并的具体逻辑，如果对其他结果集合并逻辑感兴趣的看看 MergedResult 的其他实现。 总结 最后再重新看一下这张流程图，可以很清晰的发现代码的设计完全与这张流程图一致，主要流程 SQL 解析 -&gt; 分片路由 -&gt; SQL 改写 -&gt; SQL 执行 -&gt; 结果合并。 注：由于文章篇幅有限，没有贴完整代码，并且分片路由算法、读写分离负载均衡、加密脱敏、事务相关都未详讲，有兴趣之后再单独拆一篇文章出来详讲。 参考： https://shardingsphere.apache.org/document/current/cn/reference/architecture/ https://juejin.cn/post/7343161077062991882?searchId=20240721230809FB22ACC70520144A6608#heading-28","categories":[],"tags":[]},{"title":"记一次 opentelemetry 日志打印 traceId 缺失问题分析","slug":"记一次-opentelemetry-日志打印-traceId-缺失问题分析","date":"2024-08-05T03:51:33.000Z","updated":"2024-08-05T04:05:40.501Z","comments":true,"path":"2024/08/05/记一次-opentelemetry-日志打印-traceId-缺失问题分析/","link":"","permalink":"http://example.com/2024/08/05/%E8%AE%B0%E4%B8%80%E6%AC%A1-opentelemetry-%E6%97%A5%E5%BF%97%E6%89%93%E5%8D%B0-traceId-%E7%BC%BA%E5%A4%B1%E9%97%AE%E9%A2%98%E5%88%86%E6%9E%90/","excerpt":"","text":"背景：项目中有一些消费 kafka 消息者打印的日志中缺失 traceId，项目中使用的是 javaagent 的方式接入 opentelemetry，使用的版本是 1.4.x。 Kafka 生产者首先看看生产者消息发送方法的方法增强 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354public static class ProducerAdvice &#123; @Advice.OnMethodEnter(suppress = Throwable.class) public static void onEnter( @Advice.FieldValue(\"apiVersions\") ApiVersions apiVersions, @Advice.Argument(value = 0, readOnly = false) ProducerRecord&lt;?, ?&gt; record, @Advice.Argument(value = 1, readOnly = false) Callback callback, @Advice.Local(\"otelContext\") Context context, @Advice.Local(\"otelScope\") Scope scope) &#123; // 获取当前线程上下文 Context parentContext = Java8BytecodeBridge.currentContext(); // 生成 context (包括生成 span) context = tracer().startProducerSpan(parentContext, record); callback = new ProducerCallback(callback, parentContext, context); // 判断是否需要传播链路 if (tracer().shouldPropagate(apiVersions)) &#123; try &#123; // 往请求头中添加 span 信息 tracer().inject(context, record.headers(), SETTER); &#125; catch (IllegalStateException e) &#123; // headers must be read-only from reused record. try again with new one. record = new ProducerRecord&lt;&gt;( record.topic(), record.partition(), record.timestamp(), record.key(), record.value(), record.headers()); tracer().inject(context, record.headers(), SETTER); &#125; &#125; // 将生成的 context 设置到当前上下文（默认使用threadLocal） scope = context.makeCurrent(); &#125; @Advice.OnMethodExit(onThrowable = Throwable.class, suppress = Throwable.class) public static void stopSpan( @Advice.Thrown Throwable throwable, @Advice.Local(\"otelContext\") Context context, @Advice.Local(\"otelScope\") Scope scope) &#123; // 将当前上下文清空，并恢复到父上下文（如果存在的话） scope.close(); if (throwable != null) &#123; tracer().endExceptionally(context, throwable); &#125; // span finished by ProducerCallback &#125; &#125; 从上述源码可以看到： 方法增强会在发送消息前生成 context，如果存在 parentContext 则使用 parentContext 的 traceId。 如果支持传播，则会将 span 组装好放到消息 header，具体参数名看使用的是什么协议，默认是 traceparent，这里使用 jaeger，所以参数名是 uber-trace-id。 将生成的 context 设置到当前线程上下文 消息发送结束时会将线程上下文恢复到原本的上下文 Producer traceId 消息缺失分析 由于当前不存在上下文，生产者在发送完消息后就直接将上下文清空了，所以后续打印的日志都不存在上下文 通过 callback 打印日志，由于 callback 是在另外一个线程执行，所以也获取不到上下文 Kafka 消费者首先看看消费者消息消费方法的方法增强 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118public void transform(TypeTransformer transformer) &#123; transformer.applyAdviceToMethod( isMethod() .and(isPublic()) .and(named(\"records\")) .and(takesArgument(0, String.class)) .and(returns(Iterable.class)), KafkaConsumerInstrumentation.class.getName() + \"$IterableAdvice\"); transformer.applyAdviceToMethod( isMethod() .and(isPublic()) .and(named(\"records\")) .and(takesArgument(0, named(\"org.apache.kafka.common.TopicPartition\"))) .and(returns(List.class)), KafkaConsumerInstrumentation.class.getName() + \"$ListAdvice\"); transformer.applyAdviceToMethod( isMethod() .and(isPublic()) .and(named(\"iterator\")) .and(takesArguments(0)) .and(returns(Iterator.class)), KafkaConsumerInstrumentation.class.getName() + \"$IteratorAdvice\"); &#125; @SuppressWarnings(\"unused\") public static class IterableAdvice &#123; @Advice.OnMethodExit(suppress = Throwable.class) public static void wrap( @Advice.Return(readOnly = false) Iterable&lt;ConsumerRecord&lt;?, ?&gt;&gt; iterable) &#123; if (iterable != null) &#123; // 覆盖迭代器 iterable = new TracingIterable(iterable, tracer()); &#125; &#125; &#125; @SuppressWarnings(\"unused\") public static class ListAdvice &#123; @Advice.OnMethodExit(suppress = Throwable.class) public static void wrap(@Advice.Return(readOnly = false) List&lt;ConsumerRecord&lt;?, ?&gt;&gt; iterable) &#123; if (iterable != null) &#123; // 覆盖List iterable = new TracingList(iterable, tracer()); &#125; &#125; &#125; @SuppressWarnings(\"unused\") public static class IteratorAdvice &#123; @Advice.OnMethodExit(suppress = Throwable.class) public static void wrap( @Advice.Return(readOnly = false) Iterator&lt;ConsumerRecord&lt;?, ?&gt;&gt; iterator) &#123; if (iterator != null) &#123; // 覆盖迭代器 iterator = new TracingIterator(iterator, tracer()); &#125; &#125; &#125; public class TracingIterator implements Iterator&lt;ConsumerRecord&lt;?, ?&gt;&gt; &#123; private final Iterator&lt;ConsumerRecord&lt;?, ?&gt;&gt; delegateIterator; private final KafkaConsumerTracer tracer; /** * Note: this may potentially create problems if this iterator is used from different threads. But * at the moment we cannot do much about this. */ @Nullable private Context currentContext; @Nullable private Scope currentScope; public TracingIterator( Iterator&lt;ConsumerRecord&lt;?, ?&gt;&gt; delegateIterator, KafkaConsumerTracer tracer) &#123; this.delegateIterator = delegateIterator; this.tracer = tracer; &#125; @Override public boolean hasNext() &#123; closeScopeAndEndSpan(); return delegateIterator.hasNext(); &#125; @Override public ConsumerRecord&lt;?, ?&gt; next() &#123; // in case they didn't call hasNext()... // 清除上一条消息的上下文 closeScopeAndEndSpan(); ConsumerRecord&lt;?, ?&gt; next = delegateIterator.next(); if (next != null) &#123; // 生成上下文，包含span，如果消息有上下文则提取 currentContext = tracer.startSpan(next); currentScope = currentContext.makeCurrent(); &#125; return next; &#125; private void closeScopeAndEndSpan() &#123; if (currentScope != null) &#123; currentScope.close(); currentScope = null; tracer.end(currentContext); currentContext = null; &#125; &#125; @Override public void remove() &#123; delegateIterator.remove(); &#125;&#125; 从上述源码可以看到： 迭代器每获取下一个元素，会先清除上下文，然后再生成新的上下文，如果消息头有上下文信息则提取 每次判断 hasNext 是都会清除上下文，所以遍历时循环结束，上下文也会被清除 Consumer traceId 消息缺失分析 同上在消费消息时，会使用 foreach，如果逻辑不在 foreach 之间，则会造成 traceId 缺失。 有的是使用线程池，同样会造成 traceId 缺失 Opentelemetry 日志上下文同样是先看看源码 1234567891011121314151617181920212223public class OpenTelemetryContextDataProvider implements ContextDataProvider &#123; /** * Returns context from the current span when available. * * @return A map containing string versions of the traceId, spanId, and traceFlags, which can then * be accessed from layout components */ @Override public Map&lt;String, String&gt; supplyContextData() &#123; Span currentSpan = Span.current(); if (!currentSpan.getSpanContext().isValid()) &#123; return Collections.emptyMap(); &#125; Map&lt;String, String&gt; contextData = new HashMap&lt;&gt;(); SpanContext spanContext = currentSpan.getSpanContext(); contextData.put(TRACE_ID, spanContext.getTraceId()); contextData.put(SPAN_ID, spanContext.getSpanId()); contextData.put(TRACE_FLAGS, spanContext.getTraceFlags().asHex()); return contextData; &#125;&#125; 从源码中可以看出，不是使用的 MDC，另外可以尝试使用下面方式使用自定义的上下文数据存储（亲测不行，这个可以通过修改源码解决） 1java -javaagent:path/to/opentelemetry-javaagent.jar -Dio.opentelemetry.context.contextStorageProvider=your.package.CustomContextStorageProvider -jar your-application.jar","categories":[],"tags":[]},{"title":"Antlr4 初探","slug":"Antlr4-初探","date":"2024-07-28T08:59:57.000Z","updated":"2024-07-28T09:47:06.856Z","comments":true,"path":"2024/07/28/Antlr4-初探/","link":"","permalink":"http://example.com/2024/07/28/Antlr4-%E5%88%9D%E6%8E%A2/","excerpt":"","text":"最近在看 Shardingjdbc 源码，其中 Sql 使用的语法解析器是 Antlr4，经过了解许多框架都使用 Antlr4 作为语法解析器。 简介Antlr 全称（ANother Tool for Language Recognition），是一款强大的语法分析器生成工具，像推特、Hadoop、Oracle 等知名公司都在使用它来构建自己的语言处理类项目。 一门语言的正式描述称为语法，Antlr 可以为语言生成词法分析器，并自动建立语法分析树和树的遍历器，然后我们就能访问树的节点，执行自定义业务逻辑代码。 在实际使用 Antlr 时，我们不需要关心词法分析和语法分析的过程，只需定义语法规则以及处理最后的语法分析树即可。例如，可以通过环境配置（如使用 Idea 插件）、引入相关依赖（如在 Pom 文件中添加 Antlr 依赖）、编写自定义业务逻辑等步骤来实现基于 Antlr 的应用。 基本概念词法分析器 (Lexer) 词法分析是指在计算机科学中，将字符序列转换为单词（Token）的过程，简单理解就是分词的过程。 所谓 Token ，就是源文件中不可再进一步分割的一串字符，类似于英语中单词，或汉语中的词。 ==词法分析器 (Lexer) 就是根据规则将文本（字符流）转换为单词（Token）的程序。== 语法解析器 (Parser) 词法分析完成后，字符流就被转换为 Token 流了，接下来根据语言的语法规则来解析这个 Token 流，被称为语法解析。 语法解析器通常作为编译器或解释器出现。==它的作用是进行语法检查，并将词法分析器（Lexer）输出的 Token 流解析成一个抽象语法树。== 抽象语法树 (Abstract Syntax Tree,AST)抽象语法树是源代码结构的一种抽象表示，它以树的形状表示语言的语法结构。抽象语法树一般可以用来进行代码语法的检查，代码风格的检查，代码的格式化，代码的高亮，代码的错误提示以及代码的自动补全等等。 Antlr Grammar文件简介下面是一个简单的 Grammar 文件 Expr.g4，定义了一个简单的四则运算语法规则。 123456789grammar Expr;prog: expr EOF ;expr: expr (&#39;*&#39;|&#39;&#x2F;&#39;) expr #MultiOrDiv | expr (&#39;+&#39;|&#39;-&#39;) expr #AddOrSub | INT #Lieteral | &#39;(&#39; expr &#39;)&#39; #Single ;NEWLINE : [\\r\\n]+ -&gt; skip;INT : [0-9]+ ; grammar Expr: 声明一个名为 Expr 的语法规则 Grammar 文件中以小写字母开头的为语法规则，以大写字母开头的为词法规则，那么本规则中语法规则有 prog、expr，词法规则有 NEWLINE、INT prog: 定义了一个语法规则，定义了一个 expr 表达式，后面跟着 EOF 标识文件结束 expr: 定义了一个递归语法规则，标识可以匹配 n+n、n*n、n-n、n/n、(n) 这样的四则运算，其中 n 必须是 INT，规则 prog 引用的表达式 expr 就是本规则。 NEWLINE: 定义了一个词法规则，表示条规一个或多个回车或换行符。 INT: 定义了一个词法规则，表示一个或多个 0-9 的数字 DEMO安装 Antlr安装 Anltr 的方式有很多种，可以安装系统命令行工具，也可以是 ide 插件，本文安装的是 idea 插件。其他方式可以参考 传送门。 配置也很简单，我这主要配了根据规则生成的代码路径、已经生成的代码语言。 编写 Grammer 文件这里直接使用上述讲解中使用的语法文件 12345678910grammar Expr;package org.apache.shardingsphere.example.parser.demo;prog: expr EOF ;expr: expr (&#39;*&#39;|&#39;&#x2F;&#39;) expr #MultiOrDiv | expr (&#39;+&#39;|&#39;-&#39;) expr #AddOrSub | INT #Lieteral | &#39;(&#39; expr &#39;)&#39; #Single ;NEWLINE : [\\r\\n]+ -&gt; skip;INT : [0-9]+ ; 使用插件解析语法树 根据 Grammer 文件生成代码 其中文件的含义： ExprParser: 包含语法分析器的定义，专门用来识别我们的语言。 ExprLexer: 词法分析器的定义，将输入字符分解为词汇符号； ExprLexer.tokens: antlr4 会将我们定义的词法符号指定一个数字类型，然后将对应的关系存储在这个文件中。 ExprListener: antlr4 在遍历语法树的时候，遍历器会触发一系列的事件，通知我们的监听器；ExprListener 是监听器的接口定义 ExprBaseListener 是监听器的空实现。 ExprVisitor: 如果我们想要自己显示的自定义遍历语法树，可以使用 Visitor 来遍历树，ExprBaseVistor 是默认的空实现。 ==生成代码后，还需要引入对应的依赖== 12345&lt;dependency&gt; &lt;groupId&gt;org.antlr&lt;/groupId&gt; &lt;artifactId&gt;antlr4&lt;/artifactId&gt; &lt;version&gt;4.13.1&lt;/version&gt;&lt;/dependency&gt; 编写主程序12345678910111213141516171819202122232425262728public class ExprDemo &#123; public static void main(String[] args) &#123; // 构建字符流 CodePointCharStream charStream = CharStreams.fromString(\"1+2+3*4\"); // 从字符流分析词法， 解析为token ExprLexer lexer = new ExprLexer(charStream); // 从token进行分析 ExprParser parser = new ExprParser(new CommonTokenStream( lexer) ); // 使用监听器，遍历语法树，根据语法定义，prog为语法树的根节点 ExprParser.ProgContext prog = parser.prog(); ParseTreeWalker walker = new ParseTreeWalker(); walker.walk( new ExprBaseListener(), prog ); // 使用visitor，生成自定义的对象 Object accept = prog.accept(new ExprBaseVisitor&lt;&gt;()); System.out.println(accept); // 打印生成的语法树 System.out.println( prog.toStringTree(parser)); &#125;&#125; 自定义 Visitor12345678910111213141516171819202122232425262728293031323334353637383940public class EvalExprVisitor extends ExprBaseVisitor&lt;Integer&gt; &#123; @Override public Integer visitProg(ExprParser.ProgContext ctx) &#123; ExprParser.ExprContext expr = ctx.expr(); return visit(expr); &#125; @Override public Integer visitAddOrSub(ExprParser.AddOrSubContext ctx) &#123; Integer expr1 = visit(ctx.expr(0)); Integer expr2 = visit(ctx.expr(1)); if (\"+\".equals(ctx.getChild(1).getText())) &#123; return expr1 + expr2; &#125; else &#123; return expr1 - expr2; &#125; &#125; @Override public Integer visitSingle(ExprParser.SingleContext ctx) &#123; return visit(ctx.expr()); &#125; @Override public Integer visitLieteral(ExprParser.LieteralContext ctx) &#123; return Integer.valueOf(ctx.INT().getText()); &#125; @Override public Integer visitMultiOrDiv(ExprParser.MultiOrDivContext ctx) &#123; Integer expr1 = visit(ctx.expr(0)); Integer expr2 = visit(ctx.expr(1)); if (\"*\".equals(ctx.getChild(1).getText())) &#123; return expr1 * expr2; &#125; else &#123; return expr1 / expr2; &#125; &#125;&#125; 验证结果123456789101112131415161718192021222324252627282930313233343536373839public class ExprDemo2 &#123; public static void main(String[] args) &#123; List&lt;String&gt; testSet = Arrays.asList( \"1+2\", \"1+2+3*4\", \"3/3\", \"10/2\", \"5*5+10+5*5\", \"6+5*(1+2)\" ); List&lt;Integer&gt; res = Arrays.asList( 3, 15, 1, 5, 60, 21 ); for (int i = 0; i &lt; testSet.size(); i++) &#123; // 构建字符流 CodePointCharStream charStream = CharStreams.fromString(testSet.get(i)); // 从字符流分析词法， 解析为token ExprLexer lexer = new ExprLexer(charStream); // 从token进行分析 ExprParser parser = new ExprParser(new CommonTokenStream(lexer)); // 使用监听器，遍历语法树，根据语法定义，prog为语法树的根节点 ExprParser.ProgContext prog = parser.prog(); // 使用visitor，生成自定义的对象 Integer integer = prog.accept(new EvalExprVisitor()); System.out.println(integer); Assert.assertEquals(integer, res.get(i)); &#125; &#125;&#125; 到此，上述的内容已经足以满足我研究 Shardingjdbc 的 Sql 语法解析了，如果对 Listener 感兴趣的可以参考 传送门 参考 https://github.com/antlr/antlr4/blob/master/doc/index.md https://iamazy.github.io/2020/02/12/antlr4-jiao-cheng/ https://juejin.cn/post/7174054658460090381?searchId=20240727211235DCC7CEBC417B312D14AF 注：本文中的例子引用自 https://juejin.cn/post/7174054658460090381?searchId=20240727211235DCC7CEBC417B312D14AF","categories":[],"tags":[]},{"title":"shardingjdbc 数据分片笔记","slug":"shardingjdbc-数据分片笔记","date":"2024-06-29T13:12:00.000Z","updated":"2024-06-29T13:34:31.709Z","comments":true,"path":"2024/06/29/shardingjdbc-数据分片笔记/","link":"","permalink":"http://example.com/2024/06/29/shardingjdbc-%E6%95%B0%E6%8D%AE%E5%88%86%E7%89%87%E7%AC%94%E8%AE%B0/","excerpt":"","text":"分片路由引擎org.apache.shardingsphere.core.route.type.RoutingEngine 具体选择什么分片路由引擎取决于执行的 sql org.apache.shardingsphere.core.route.router.sharding.ShardingRouter#route 分片路由策略org.apache.shardingsphere.core.strategy.route.ShardingStrategy org.apache.shardingsphere.core.strategy.route.none.NoneShardingStrategy 不进行分片路由 org.apache.shardingsphere.core.strategy.route.none.NoneShardingStrategy 根据行表达式路由，不支持按条件范围分片 org.apache.shardingsphere.core.strategy.route.standard.StandardShardingStrategy 经典分片策略，内置按值分片算法，按范围分配算法 org.apache.shardingsphere.core.strategy.route.complex.ComplexShardingStrategy 组合条件分片策略，逻辑需要执行实现，==同时如果某些逻辑 StandardShardingStrategy 无法实现也可以考虑使用 ComplexShardingStrategy==。 org.apache.shardingsphere.core.strategy.route.hint.HintShardingStrategy 强制分片策略，适合需要按照分数据库的列进行分片的场景，比如根据 来源ip 进行分片，底层基于 ThreadLocal 实现，需要在执行 sql 前指定分片值。 使用 DEMO1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283package org.apache.shardingsphere.example.sharding.raw.jdbc.config;import org.apache.shardingsphere.api.config.sharding.KeyGeneratorConfiguration;import org.apache.shardingsphere.api.config.sharding.ShardingRuleConfiguration;import org.apache.shardingsphere.api.config.sharding.TableRuleConfiguration;import org.apache.shardingsphere.api.config.sharding.strategy.ComplexShardingStrategyConfiguration;import org.apache.shardingsphere.api.config.sharding.strategy.StandardShardingStrategyConfiguration;import org.apache.shardingsphere.api.sharding.complex.ComplexKeysShardingAlgorithm;import org.apache.shardingsphere.api.sharding.complex.ComplexKeysShardingValue;import org.apache.shardingsphere.core.constant.properties.ShardingPropertiesConstant;import org.apache.shardingsphere.example.algorithm.PreciseModuloShardingTableAlgorithm;import org.apache.shardingsphere.example.config.ExampleConfiguration;import org.apache.shardingsphere.example.core.api.DataSourceUtil;import org.apache.shardingsphere.shardingjdbc.api.ShardingDataSourceFactory;import javax.sql.DataSource;import java.sql.SQLException;import java.util.*;public final class ShardingMultiDatabasesAndTablesConfigurationPrecise implements ExampleConfiguration &#123; @Override public DataSource getDataSource() throws SQLException &#123; ShardingRuleConfiguration shardingRuleConfig = new ShardingRuleConfiguration(); shardingRuleConfig.getTableRuleConfigs().add(getOrderTableRuleConfiguration()); shardingRuleConfig.getTableRuleConfigs().add(getOrderItemTableRuleConfiguration()); shardingRuleConfig.getBindingTableGroups().add(\"t_order, t_order_item\"); shardingRuleConfig.getBroadcastTables().add(\"t_address\");// shardingRuleConfig.setDefaultDatabaseShardingStrategyConfig(new InlineShardingStrategyConfiguration(\"user_id\", \"demo_ds_$&#123;user_id % 2&#125;\")); shardingRuleConfig.setDefaultDatabaseShardingStrategyConfig(new ComplexShardingStrategyConfiguration(\"user_id\", new CustomComplexKeysShardingAlgorithm())); shardingRuleConfig.setDefaultTableShardingStrategyConfig(new StandardShardingStrategyConfiguration(\"order_id\", new PreciseModuloShardingTableAlgorithm())); Properties props = new Properties(); props.put(ShardingPropertiesConstant.SQL_SHOW.getKey(), true); return ShardingDataSourceFactory.createDataSource(createDataSourceMap(), shardingRuleConfig, props); &#125; private static TableRuleConfiguration getOrderTableRuleConfiguration() &#123; TableRuleConfiguration result = new TableRuleConfiguration(\"t_order\", \"demo_ds_$&#123;0..1&#125;.t_order_$&#123;[0, 1]&#125;\"); result.setKeyGeneratorConfig(new KeyGeneratorConfiguration(\"SNOWFLAKE\", \"order_id\", getProperties())); return result; &#125; private static TableRuleConfiguration getOrderItemTableRuleConfiguration() &#123; TableRuleConfiguration result = new TableRuleConfiguration(\"t_order_item\", \"demo_ds_$&#123;0..1&#125;.t_order_item_$&#123;[0, 1]&#125;\"); result.setKeyGeneratorConfig(new KeyGeneratorConfiguration(\"SNOWFLAKE\", \"order_item_id\", getProperties())); return result; &#125; private static Map&lt;String, DataSource&gt; createDataSourceMap() &#123; Map&lt;String, DataSource&gt; result = new HashMap&lt;&gt;(); result.put(\"demo_ds_0\", DataSourceUtil.createDataSource(\"demo_ds_0\")); result.put(\"demo_ds_1\", DataSourceUtil.createDataSource(\"demo_ds_1\")); return result; &#125; private static Properties getProperties() &#123; Properties result = new Properties(); result.setProperty(\"worker.id\", \"123\"); return result; &#125; public static class CustomComplexKeysShardingAlgorithm implements ComplexKeysShardingAlgorithm&lt;Integer&gt; &#123; @Override public Collection&lt;String&gt; doSharding(Collection&lt;String&gt; availableTargetNames, ComplexKeysShardingValue&lt;Integer&gt; shardingValue) &#123; List&lt;String&gt; result = new ArrayList&lt;&gt;(); shardingValue.getColumnNameAndShardingValuesMap().forEach((column, valueList) -&gt; &#123; if (Objects.equals(column, \"user_id\")) &#123; valueList.forEach(value -&gt; &#123; if (value % 2 == 1) &#123; result.addAll(availableTargetNames); &#125; else &#123; Optional&lt;String&gt; optional = availableTargetNames.stream().filter(name -&gt; name.endsWith(String.valueOf(value % 2))).findFirst(); optional.ifPresent(result::add); &#125; &#125;); &#125; &#125;); return result; &#125; &#125;&#125; 注意事项 ==如果 sql 语句没有命中分片条件，将在所有的物理表中执行 sql== hint 必须要在执行 sql 前设置条件值，否则会和上述一样因未命中分片条件而在所有物理表执行 sql 目前支持原生的分片策略，如果要支持自定义的可能得把大部分上游组件给改了 支持很多 sqi 扩展钩子，例如 org.apache.shardingsphere.sql.parser.hook.SPIParsingHook","categories":[],"tags":[]},{"title":"记录一次增量数据一致性问题","slug":"记录一次增量数据一致性问题","date":"2023-11-19T02:11:45.000Z","updated":"2023-11-19T15:11:48.859Z","comments":true,"path":"2023/11/19/记录一次增量数据一致性问题/","link":"","permalink":"http://example.com/2023/11/19/%E8%AE%B0%E5%BD%95%E4%B8%80%E6%AC%A1%E5%A2%9E%E9%87%8F%E6%95%B0%E6%8D%AE%E4%B8%80%E8%87%B4%E6%80%A7%E9%97%AE%E9%A2%98/","excerpt":"","text":"最近收到客户投诉出现数据无法操作的问题，经过排查，Mysql 和 ES 数据出现一致性问题。我们的使用场景是定于 Mysql binlog 投递到 Kafka，增量服务顺序消费 Kafka 中的消息，更新 ES 中的文档。 索引结构在分析问题前先简单看下索引结构，这里只看出现问题的字段，主要就是用于存储标签 id 的一个 long 类型的字段，存的是一个数组。 12345678910&#123; \"mappings\" : &#123; \"f_tag_id\" : &#123; \"type\" : \"long\" &#125;, \"f_status\" : &#123; \"type\" : \"byte\" &#125; &#125;&#125; 问题分析 先简单看一下标签增量的逻辑，由于标签存的是一个数组，所以在更新的时候是先把文档查询出来，再对相应的数组字段做元素的新增或者删除，然后再重新索引到 ES 中。 生产中的场景是同时有两个 binlog 并发，但是是分两次消费（同一批次的消息我们这边会在内存进行组装），A 表的 binlog 先更新 f_status，B 表 (标签关联表) 的 binlog 先将文档查询出来，更新完之后再将整个文档索引回 ES（更新代码通用性，所以是更新整个文档）。 由于 ES 索引更新刷盘并非实时的，导致 B 表查询出来的文档是旧的，所以 B 表在更新索引时将旧的数据覆盖了新的数据。 举一个简单的例子： 假设原本 f_status = 0, f_tag_id = [] A 表更新 f_status =1，此时 f_status = 1, f_tag_id = [] B 表更新 f_tag_id = [1]，由于 ES 刷盘存在延迟，导致更新的数据为 f_status = 0, f_tag_id = [1] 解决方案 最初的想法是只更新 f_tag_id 字段，但是这样其实还是会有问题，举个例子 B 表 (标签关联表) 针对同一条记录两个标签关联数据，意味着会有两个 binlog 生成，假设很不巧，Kafka 消费者分了两个批次去更新索引，就会造成和上述类似的场景。 假设原本 f_tag_id = [1,2] 第一条 binlog 更新 f_tag_id = [1,2,3] 第二条 binlog 消费时，先查询 f_tag_id = [1,2]，此时在去更新 f_tag_id 就会变成 [1,2,4]，还是会出现数据不一致问题 第一个方案行不通，那能不能让 f_tag_id 像更新其他字段一样，不需要先查询出来组装再重新索引回 ES，答案是可以，那就是利用 ES 脚本更新，因为更新操作是可以直接更新内存的数据，所以数据是实时的。 12345678910111213141516171819202122232425&#123; \"script\": &#123; \"source\": \"\"\" List tagIdList = ctx._source.f_tag_id == null ? new ArrayList() : ctx._source.f_tag_id; if(\"insert\".equals(params.method) &amp;&amp; !tagIdList.contains(params.changeTagId))&#123; tagIdList.add(params.changeTagId); &#125; else if(\"delete\".equals(params.method) &amp;&amp; tagIdList.contains(params.changeTagId))&#123; tagIdList.remove(tagIdList.indexOf(params.changeTagId)); &#125; ctx._source.f_tag_id = tagIdList; \"\"\", \"lang\": \"painless\", \"params\": &#123; \"changeTagId\": 12, \"method\": \"insert\" &#125; &#125;, \"upsert\": &#123; \"f_tag_id\": [12] &#125;&#125; 大概思路就是利用脚本直接针对 f_tag_id 进行元素变更，这样就不用担心查出来的 f_tad_id 是旧的了。 参考https://www.elastic.co/guide/en/elasticsearch/reference/7.14/docs-update.htmlhttps://www.elastic.co/guide/en/elasticsearch/painless/7.14/painless-types.html","categories":[],"tags":[{"name":"ES","slug":"ES","permalink":"http://example.com/tags/ES/"}]},{"title":"分布式事务之 2PC 的 XA 规范实现","slug":"分布式事务之-2PC-的-XA-规范实现","date":"2023-07-25T02:11:00.000Z","updated":"2023-07-25T02:16:46.841Z","comments":true,"path":"2023/07/25/分布式事务之-2PC-的-XA-规范实现/","link":"","permalink":"http://example.com/2023/07/25/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E4%B9%8B-2PC-%E7%9A%84-XA-%E8%A7%84%E8%8C%83%E5%AE%9E%E7%8E%B0/","excerpt":"","text":"刚开始学习分布式事务时，第一个解决方案就是 2PC，但是一直没有写过 demo，也没有生产中使用过这种方案，随意是既熟悉又陌生。本文只在实现一个 2PC XA方案的 demo，万一将来需要用到这种方案不至于少也不懂。 2PC 简介2PC 主要分为两个阶段，准备阶段、提交阶段。 准备阶段：TM（事务管理器）向 RM（资源管理器）发送 Prepare 消息，RM 本地执行事务，此时 RM 并未提交本地事务（上锁），RM 发送执行成功/失败给到 TM 提交阶段：TM 向 RM 发送 Commit/Rollback 消息，RM 根据 TM 发送的消息执行提交或回滚本地事务。 以下是网上找的一张 2PC 的流程图： XA 方案 2PC 的传统方案是在数据库层面实现的，如 Oracle、MySQL 都支持 2PC 协议，为了统一标准减少行业内不必要的对接成本，需要制定标准化的处理模型及接口标准，国际开放标准组织 Open Group 定义了分布式事务处理模型DTP（Distributed Transaction Processing Reference Model）。 DTP 模型定义如下角色： AP（Application Program）：即应用程序，可以理解为使用 DTP 分布式事务的程序。 RM（Resource Manager）：即资源管理器，可以理解为事务的参与者，一般情况下是指一个数据库实例，通过资源管理器对该数据库进行控制，资源管理器控制着分支事务。 TM（Transaction Manager）：事务管理器，负责协调和管理事务，事务管理器控制着全局事务，管理事务生命周期，并协调各个 RM。全局事务是指分布式事务处理环境中，需要操作多个数据库共同完成一个工作，这个工作即是一个全局事务。 DTP 模型定义TM和RM之间通讯的接口规范叫 XA，简单理解为数据库提供的 2PC 接口协议，基于数据库的 XA 协议来实现 2PC 又称为 XA 方案 XA 执行流程：（作者比较懒，什么都没留下） 流程可以参看大佬的博客：https://zhuanlan.zhihu.com/p/263555694 具体实现： Java事务API（JTA：Java Transaction API）和它的同胞Java事务服务（JTS：Java Transaction Service），为J2EE平台提供了分布式事务服务（distributed transaction）的能力。 某种程度上，可以认为JTA规范是XA规范的Java版，其把XA规范中规定的DTP模型交互接口抽象成Java接口中的方法，并规定每个方法要实现什么样的功能。 下面的例子基于 Atomikos TransactionEssentials 实现 JTA： 所需要依赖，这里用的 Gradle，用的 Maven 家人们可以自行找下依赖 123456789101112implementation platform('org.springframework.boot:spring-boot-dependencies:2.7.5')implementation 'com.atomikos:transactions-jdbc:6.0.0'implementation 'com.atomikos:transactions-jta:6.0.0'implementation 'javax.transaction:jta:1.1'implementation 'com.alibaba:druid:1.2.18'implementation 'org.springframework.boot:spring-boot-starter-web'implementation 'org.springframework.boot:spring-boot-test'implementation 'org.springframework.boot:spring-boot-starter-test'implementation 'org.mybatis.spring.boot:mybatis-spring-boot-starter:2.2.1'implementation 'org.springframework.boot:spring-boot'implementation 'org.springframework:spring-tx'implementation 'mysql:mysql-connector-java:8.0.33' 数据库配置，这里我在本地中启动了两个 Mysql 实例，数据库只要能支持 XA 协议即可 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778/** * 这里用的Druid，其他连接池只要实现了javax.sql.XADataSource即可 */public abstract class AbstractDataSourceConfig &#123; protected DruidXADataSource createDruidXADataSource(String url, String username, String password) &#123; DruidXADataSource druidXADataSource = new DruidXADataSource(); //&lt;a href=\"https://github.com/alibaba/druid/wiki/DruidDataSource%E9%85%8D%E7%BD%AE%E5%B1%9E%E6%80%A7%E5%88%97%E8%A1%A8\"/&gt; druidXADataSource.setUrl(url); druidXADataSource.setUsername(username); druidXADataSource.setPassword(password); druidXADataSource.setMaxActive(5); druidXADataSource.setInitialSize(1); druidXADataSource.setMaxWait(15000); druidXADataSource.setMinIdle(1); druidXADataSource.setTestOnBorrow(false); druidXADataSource.setTestWhileIdle(true); druidXADataSource.setValidationQuery(\"select 1\"); druidXADataSource.setTimeBetweenEvictionRunsMillis(60000); druidXADataSource.setMinEvictableIdleTimeMillis(300000); druidXADataSource.setAsyncInit(true); return druidXADataSource; &#125;&#125;/** * 这里是3306端口的实例配置 */ @Configuration@MapperScan(value = \"com.jl.demo.spring.repository.mapper.db3306\", sqlSessionFactoryRef = \"sqlSessionFactory3306\")public class DataSourceConfig3306 extends AbstractDataSourceConfig &#123; @Bean public DataSource dataSource3306() &#123; AtomikosDataSourceBean datasource = new AtomikosDataSourceBean(); DruidXADataSource druidXADataSource = createDruidXADataSource(\"jdbc:mysql://localhost:3306/xa_test\", \"root\", \"123456\"); datasource.setXaDataSource(druidXADataSource); //atomikos要求为每个AtomikosDataSourceBean名称 datasource.setUniqueResourceName(\"local_3306\"); return datasource; &#125; @Bean public SqlSessionFactory sqlSessionFactory3306() throws Exception &#123; SqlSessionFactoryBean sqlSessionFactoryBean = new SqlSessionFactoryBean(); sqlSessionFactoryBean.setDataSource(dataSource3306()); PathMatchingResourcePatternResolver resolver = new PathMatchingResourcePatternResolver(); sqlSessionFactoryBean.setMapperLocations(resolver.getResources(\"classpath:/mybatis/db3306/*.xml\")); return sqlSessionFactoryBean.getObject(); &#125;&#125;/** * 这里是3308端口的实例配置 */ @Configuration@MapperScan(value = \"com.jl.demo.spring.repository.mapper.db3308\", sqlSessionFactoryRef = \"sqlSessionFactory3308\")public class DataSourceConfig3308 extends AbstractDataSourceConfig &#123; @Bean public DataSource dataSource3308() &#123; AtomikosDataSourceBean datasource = new AtomikosDataSourceBean(); DruidXADataSource druidXADataSource = createDruidXADataSource(\"jdbc:mysql://localhost:3308/xa_test\", \"root\", \"123456\"); datasource.setXaDataSource(druidXADataSource); datasource.setUniqueResourceName(\"local_3308\"); return datasource; &#125; @Bean public SqlSessionFactory sqlSessionFactory3308() throws Exception &#123; SqlSessionFactoryBean sqlSessionFactoryBean = new SqlSessionFactoryBean(); sqlSessionFactoryBean.setDataSource(dataSource3308()); PathMatchingResourcePatternResolver resolver = new PathMatchingResourcePatternResolver(); sqlSessionFactoryBean.setMapperLocations(resolver.getResources(\"classpath:/mybatis/db3308/*.xml\")); return sqlSessionFactoryBean.getObject(); &#125;&#125; 事务相关配置，spring 已经帮我们把 JtaTransactionManager 封装好了，底层使用的是我们传入的事务管理器 1234567891011121314151617181920212223@Configurationpublic class TransactionConfig &#123; /** * 配置atomikos事务管理器 */ @Bean public UserTransactionManager userTransactionManager() &#123; UserTransactionManager userTransactionManager = new UserTransactionManager(); userTransactionManager.setForceShutdown(false); return userTransactionManager; &#125; /** * 配置jta事务管理器，底层使用atomikos事务管理器 */ @Bean public TransactionManager jtaTransactionManager() &#123; JtaTransactionManager jtaTransactionManager = new JtaTransactionManager(); jtaTransactionManager.setTransactionManager(userTransactionManager()); return jtaTransactionManager; &#125;&#125; 下面简单看一下 service 层，由于本例子主要是为了测试 Jta 是否能正确回滚两个数据库实例，所以用了两个相同的表，不含业务属性 1234567891011121314151617181920212223@Servicepublic class UserServiceImpl implements UserService &#123; @Autowired private UserMapper3306 userMapper3306; @Autowired private UserMapper3308 userMapper3308; @Override @Transactional(transactionManager = \"jtaTransactionManager\", rollbackFor = Exception.class) public void insert() &#123; User user3306 = new User(); user3306.setName(\"111\"); userMapper3306.insert(user3306); com.jl.demo.spring.repository.model.db3308.User user3308 = new com.jl.demo.spring.repository.model.db3308.User(); user3308.setName(\"222\"); userMapper3308.insert(user3308); throw new RuntimeException(\"test\"); &#125;&#125; 测试代码 123456789101112@ExtendWith(SpringExtension.class)@SpringBootTest(classes = AtomikosTestApplication.class)class UserServiceImplTest &#123; @Autowired private UserService userService; @Test void insert() &#123; userService.insert(); &#125;&#125; 仓库地址：https://github.com/JerryQTQcjl/distributed-transaction-demo/tree/master/atomikos-xa-demo 参考http://www.tianshouzhi.com/api/tutorials/distributed_transaction/386 https://github.com/atomikos/transactions-essentials","categories":[],"tags":[{"name":"分布式事务","slug":"分布式事务","permalink":"http://example.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/"}]},{"title":"聊聊双亲委派机制","slug":"聊聊双亲委派机制","date":"2023-04-29T17:17:16.000Z","updated":"2023-04-29T17:29:38.439Z","comments":true,"path":"2023/04/30/聊聊双亲委派机制/","link":"","permalink":"http://example.com/2023/04/30/%E8%81%8A%E8%81%8A%E5%8F%8C%E4%BA%B2%E5%A7%94%E6%B4%BE%E6%9C%BA%E5%88%B6/","excerpt":"","text":"最近重新看了双亲委派相关的知识，特此记录一下，方便以后重新回顾 Java 类是怎么加载Java 通过 ClassLoader 实例的 loadClass 方法将字节码（.class）文件加载到 JVM 的方法区中。啥也不说，先上代码 (～￣▽￣)～： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263 protected Class&lt;?&gt; loadClass(String name, boolean resolve) throws ClassNotFoundException &#123; synchronized (getClassLoadingLock(name)) &#123; // 从已加载的类中寻找 Class&lt;?&gt; c = findLoadedClass(name); if (c == null) &#123; try &#123; //父委派机制 if (parent != null) &#123; c = parent.loadClass(name, false); &#125; else &#123; //没有父类加载器，则说明父加载器是启动类加载器 c = findBootstrapClassOrNull(name); &#125; &#125; catch (ClassNotFoundException e) &#123; &#125; if (c == null) &#123; //根据类名从数据源查找对应的字节码，读取二进制流，生成 Class 对象 c = findClass(name); &#125; &#125; if (resolve) &#123; //官方注释说是链接一个类，这里暂时没用过，下次看看 resolveClass(c); &#125; return c; &#125; &#125;//此处贴的是 ClassLoader 子类 URLClassLoader 的 findClass 方法，也是默认的实现protected Class&lt;?&gt; findClass(final String name) throws ClassNotFoundException &#123; final Class&lt;?&gt; result; try &#123; result = AccessController.doPrivileged( new PrivilegedExceptionAction&lt;Class&lt;?&gt;&gt;() &#123; public Class&lt;?&gt; run() throws ClassNotFoundException &#123; //根据类名从资源路径查找对应的资源 String path = name.replace('.', '/').concat(\".class\"); Resource res = ucp.getResource(path, false); if (res != null) &#123; try &#123; //读取二进制流，生成 Class 对象 return defineClass(name, res); &#125; catch (IOException e) &#123; throw new ClassNotFoundException(name, e); &#125; &#125; else &#123; return null; &#125; &#125; &#125;, acc); &#125; catch (java.security.PrivilegedActionException pae) &#123; throw (ClassNotFoundException) pae.getException(); &#125; if (result == null) &#123; throw new ClassNotFoundException(name); &#125; return result; &#125; 从上面的代码可以看到 loadClass 主要做了两件事情： 根据类名从资源路径（文件、网络等）查找对应的字节码资源 从资源路径读取字节码二进制流，并生成对应的 Class 对象，其中包括权限校验，字节码校验等。 Java 默认的类加载器JDK9 之前默认的类加载器有：AppClassLoader、ExtClassLoader、BootstrapClassloader BootstrapClassLoader: JRE 的 lib 目录下 jar 包中的类（以及由虚拟机参数 -Xbootclasspath 指定的类），注意，他不是定义在 Java 代码中的。 ExtClassLoader：存放在 JRE 的 lib/ext 目录下 jar 包中的类（以及由系统变量 java.ext.dirs 指定的类）。 AppClassLoader：负责加载应用程序路径下的类（虚拟机参数 -cp/-classpath、系统变量 java.class.path 或环境变量 CLASSPATH 所指定的路径） JDK9 及以后默认的类加载器：AppClassLoader、PlatformClassLoader、BootstrapClassLoader PlatformClassLoader：其实就是之前的 ExtClassLoader，只是将大部分原本由 BootstrapClassLoader 加载的类交由 PlatformClassLoader 加载 Java 类的加载时机有哪些类加载的时机有很多，这里主要列举一些易错场景 (～￣▽￣)～： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public class ClassLoadTimingTest &#123; public static void main(String[] args) throws ClassNotFoundException &#123; //new一个对象实例 new A(); //加载A //通过反射实例化一个对象 Class.forName(\"com.classloader.demo.char01.A\"); //加载A //访问类的静态变量 System.out.println(A.word); //加载A //访问类的静态方法 A.println(); //加载A //子类初始化会触发父类初始化 System.out.println(B.word1); //加载A、B //以下情况不加载 System.out.println(B.word); //加载A，不加载B //创建数组不加载类 System.out.println(new A[]&#123;&#125;); //不加载A //访问常量不加载类 System.out.println(A.DEFAULT); //不加载A //易混淆情况，编译器无法确定最终变量的值，所以运行期要去加载 System.out.println(A.DEFAULT1); //加载A &#125;&#125;class A&#123; protected final static String DEFAULT = \"HELLO WORLD\"; protected final static String DEFAULT1 = new String(\"123\"); public static String word = \"HELLO WORLD\"; static &#123; System.out.println(\"A was loader\"); &#125; public static void println()&#123;&#125;&#125;class B extends A&#123; public static String word1 = \"HELLO WORLD\"; static &#123; System.out.println(\"B was loader\"); &#125;&#125; 什么是双亲委派机制仔细的同学应该会发现，上面加载类的方法中，优先会调用 parent.loadClass 去加载类，如果没加载到才会走继续往下走。 其实这就是类加载的父委派机制，优先由父加载器去加载类，父类加载器没加载到才有自身尝试去加载。 那么什么是双亲委派机制呢，还记得上面提到 JDK8 的默认类加载器有 AppClassLoader、ExtClassLoader、BootstrapClassloader，BootstrapClassloader 是 ExtClassLoader 的父加载器，ExtClassLoader 是 AppClassLoader 的父加载器。嗯，就是因为 AppClassLoader 有一个爸爸和一个爷爷，所以称为双亲委派机制。就是这么简单 ︿(￣︶￣)︿。 那么双亲委派机制的作用是什么呢，我认为有两点： 防止同一个类被加载到 JVM 多次 避免 Java 内部的一些基础类没有被正确加载，导致出现难以意料的异常 JDBC 真的打破双亲委派了吗在说 JDBC 是否打破双亲委派之前我们先来聊聊什么是打破双亲委派机制，嗯，就是让类的加载顺序不在是 BootstrapClassloader -&gt; ExtClassLoader -&gt; AppClassLoader，就是字面上的意思不再让爷爷和爸爸先加载，而是儿子自己想先加载就先加载 ︿(￣︶￣)︿。那么我们该怎么做呢，是不是自定义一个类加载器，重写下 loadClass 方法不在调用 parent.loadClass 就可以了？嗯，是的 o(￣▽￣)ｄ。 那么我们再来看看 JDBC 真的打破双亲委派了吗。老规矩，线上代码 (～￣▽￣)～： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071AppClassLoaderpublic class DriverManager &#123; static &#123; loadInitialDrivers(); println(\"JDBC DriverManager initialized\"); &#125; private static void loadInitialDrivers() &#123; String drivers; try &#123; //获取环境变量中配置的驱动 drivers = AccessController.doPrivileged(new PrivilegedAction&lt;String&gt;() &#123; public String run() &#123; return System.getProperty(\"jdbc.drivers\"); &#125; &#125;); &#125; catch (Exception ex) &#123; drivers = null; &#125; AccessController.doPrivileged(new PrivilegedAction&lt;Void&gt;() &#123; public Void run() &#123; //通过SPI机制加载驱动类 ServiceLoader&lt;Driver&gt; loadedDrivers = ServiceLoader.load(Driver.class); Iterator&lt;Driver&gt; driversIterator = loadedDrivers.iterator(); */ try&#123; while(driversIterator.hasNext()) &#123; //这里面会加载驱动类（不初始化），但是会通过反射实例化驱动类（会初始化） driversIterator.next(); &#125; &#125; catch(Throwable t) &#123; // Do nothing &#125; return null; &#125; &#125;); println(\"DriverManager.initialize: jdbc.drivers = \" + drivers); if (drivers == null || drivers.equals(\"\")) &#123; return; &#125; String[] driversList = drivers.split(\":\"); println(\"number of Drivers:\" + driversList.length); for (String aDriver : driversList) &#123; try &#123; println(\"DriverManager.Initialize: loading \" + aDriver); //加载驱动类并初始化 Class.forName(aDriver, true, ClassLoader.getSystemClassLoader()); &#125; catch (Exception ex) &#123; println(\"DriverManager.Initialize: load failed: \" + ex); &#125; &#125; &#125;&#125;public final class ServiceLoader&lt;S&gt; &#123; private final ClassLoader loader; private LazyIterator lookupIterator; public static &lt;S&gt; ServiceLoader&lt;S&gt; load(Class&lt;S&gt; service) &#123; //拿到线程上下文中的类加载器，这里如果未设置过获取到的是 AppClassLoader ClassLoader cl = Thread.currentThread().getContextClassLoader(); return ServiceLoader.load(service, cl); &#125;&#125; 从上面的代码可以看到，DriverManager 通过 SPI 机制，加载 Driver 驱动类，而 ServiceLoader 中其实只是拿到当前上下文中的类加载器，那么能说他打破了双亲委派机制吗？我个人觉得是不能的，先不说其他，在未手动设置线程上下文中的类加载器的情况下，线程上下文类加载器是继承至父线程的，其实也就是 AppClassLoader，那正常情况下他走的就是双亲委派机制 （￣︶￣）↗。就算是将自定义的类加载器放入线程上下文中，那也是由自定义的类加载器通过重写 loadClass 打破双亲委派机制呀，所以我认为 JDBC 自身并未打破了双亲委派机制 &lt;(￣︶￣)&gt;。 Tomcat 如何打破双亲委派那么 Tomcat 打破了吗？嗯，它打破了 ｂ（￣▽￣）ｄ，Tomcat7 及以上自定义了类加载器 ParallelWebappClassLoader 和 WebappClassLoader。嗯，这里注意一下，Tomcat6 以下的类加载器有所不同，不过原理都是一样的（其实是我偷懒，不想把 Tomcat6 源码也看了 (╯▽╰)）。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071public Class&lt;?&gt; loadClass(String name, boolean resolve) throws ClassNotFoundException &#123; synchronized (JreCompat.isGraalAvailable() ? this : getClassLoadingLock(name)) &#123; String resourceName = binaryNameToPath(name, false); //这里获取到 ExtClassLoader ClassLoader javaseLoader = getJavaseClassLoader(); boolean tryLoadingFromJavaseLoader; try &#123; URL url; if (securityManager != null) &#123; PrivilegedAction&lt;URL&gt; dp = new PrivilegedJavaseGetResource(resourceName); url = AccessController.doPrivileged(dp); &#125; else &#123; //先ExtClassLoader和BoostrapClassLoader的资源路径中查找字节码资源 url = javaseLoader.getResource(resourceName); &#125; //如果资源存在则走ExtClassLoader和BoostrapClassLoader加载 tryLoadingFromJavaseLoader = (url != null); &#125; catch (Throwable t) &#123; ExceptionUtils.handleThrowable(t); tryLoadingFromJavaseLoader = true; &#125; if (tryLoadingFromJavaseLoader) &#123; try &#123; //如果资源存在则走ExtClassLoader和BoostrapClassLoader加载 clazz = javaseLoader.loadClass(name); //return &#125; catch (ClassNotFoundException e) &#123; // Ignore &#125; &#125; //判断是否需要委派给父类加载器，默认是AppClassLoader，或者是Tomcat内部的一些类 boolean delegateLoad = delegate || filter(name, true); // (1) Delegate to our parent if requested if (delegateLoad) &#123; try &#123; clazz = Class.forName(name, false, parent); //return &#125; catch (ClassNotFoundException e) &#123; // Ignore &#125; &#125; try &#123; //从本地目录中查找类并加载 clazz = findClass(name); //return &#125; catch (ClassNotFoundException e) &#123; // Ignore &#125; // (3) Delegate to parent unconditionally if (!delegateLoad) &#123; try &#123; //还是没有找到就委派给父加载器，默认是AppClassLoader clazz = Class.forName(name, false, parent); //return &#125; catch (ClassNotFoundException e) &#123; // Ignore &#125; &#125; &#125; throw new ClassNotFoundException(name);&#125; 我们看看 Tomcat 都改了啥： 首先尝试通过 ExtClassLoader 加载类，防止 java 相关的一些类被先加载了 判断是否需要委派给父类加载器，或者是是否是Tomcat内部的一些类，是的话则委派给父类加载器 从本地目录和扩展路径中查找类并加载，还记的早起我们使用 Tomcat 时，会将多个 war 包放在 webapps 吗，那么如果多个 war 中完全的全路径类名，走默认的双亲委派机制就只有先加载的能加载成功。此处便是 Tomcat 打破双亲委派意义了。 如果还是没有找到，就委派给父类加载器，走双亲委派机制。 可以看到，Tomcat 的类加载顺序不再是 BootstrapClassloader -&gt; ExtClassLoader -&gt; AppClassLoader，而是在 AppClassLoader 前先尝试通过 WebappClassLoader 加载本地目录 ｂ（￣▽￣）ｄ。 自定义类加载器篇幅有点长了，这个下次一定 ╰(￣▽￣)╭ 总结 Java 通过 ClassLoader 实例的 loadClass 方法将字节码（.class）文件加载到 JVM 的方法区中。 JDK9 之前默认的类加载器有：AppClassLoader、ExtClassLoader、BootstrapClassloader ,JDK9 及以后默认的类加载器：**AppClassLoader、PlatformClassLoader、BootstrapClassLoader **。 类加载时机包括：new一个对象实例；反射实例化一个对象；访问类的静态变量、方法；子类初始化会触发父类初始化；方法句柄调用加载方法所在类。 不加载时机：访问父类静态变量，不加载子类；创建数组不加载类；访问常量不加载类，但是如果编译是无法确定，运行期还是会加载类。 JVM 为防止同一个类被加载多次，引入双亲委派机制，加载类过程中，先由其父类加载器加载，未加载到在自己加载 JDBC 并未打破双亲委派，而 Tomcat 通过自定义 ClassLoader 打破双亲委派。","categories":[],"tags":[{"name":"jvm","slug":"jvm","permalink":"http://example.com/tags/jvm/"}]},{"title":"Spring @Validated 失效分析","slug":"Spring-Validated-失效分析","date":"2023-04-21T17:41:36.000Z","updated":"2023-04-22T06:07:27.069Z","comments":true,"path":"2023/04/22/Spring-Validated-失效分析/","link":"","permalink":"http://example.com/2023/04/22/Spring-Validated-%E5%A4%B1%E6%95%88%E5%88%86%E6%9E%90/","excerpt":"","text":"最近在落地 DDD，希望对 command 进行参数校验，由于部分流量入口是 MQ，所以希望在应用层是用 @Validated 进行参数校验，结果。。。 Controller 中使用 @Validated@Validated 注解的作用这里就不多做介绍了，具体用法在网上应该有不少。 在之前使用 MVC 架构编码时，通常是将 @Validated 注解或者 @Valid 配置在 Controller 的方法中，如下代码所示： 12345@PostMapping(\"common/set\")public Response&lt;?&gt; setCommonSetting(@RequestBody @Validated SetCommonSettingReqVO reqVO) &#123; //doSomeThings return Response.success();&#125; 所以在配置应用层校验时，就想当然的按照类似的写法： 123public void addClueTrack(@Validated AddClueTrackCommand command) &#123; //doSomeThings&#125; 结果可想而知，@Validated 注解并不生效。 @Validated 是怎么生效的？竟然不生效，那么就开始分析原因。 首先可以很容易想到，竟然能在方法执行前就拦截进行校验，那么大概率是使用动态代理。就和 @Transactional 事务注解一样，底层都是基于 AOP 实现动态代理。 接下来为了印证这个想法，就是需要深入看看 Spring 实现的。通过 IDE 可以很方便看到有哪些地方引用了 @Validated 注解： 其中一个类名一下就引起了我的注意 MethodValidationPostProcessor，熟悉 Spring 的小伙伴应该知道，Spring 中有很多 BeanPostProcessor 用于扩展 Bean，Aop 便是基于此实现动态代理的。点进去一看，果不其然： 123456789101112131415161718192021222324252627282930313233343536public class MethodValidationPostProcessor extends AbstractBeanFactoryAwareAdvisingPostProcessor implements InitializingBean &#123; private Class&lt;? extends Annotation&gt; validatedAnnotationType = Validated.class; @Nullable private Validator validator; //... @Override public void afterPropertiesSet() &#123; //创建切点 Pointcut pointcut = new AnnotationMatchingPointcut(this.validatedAnnotationType, true); this.advisor = new DefaultPointcutAdvisor(pointcut, createMethodValidationAdvice(this.validator)); &#125; protected Advice createMethodValidationAdvice(@Nullable Validator validator) &#123; //创建拦截器 return (validator != null ? new MethodValidationInterceptor(validator) : new MethodValidationInterceptor()); &#125;&#125;public class AnnotationMatchingPointcut implements Pointcut &#123; private final ClassFilter classFilter; private final MethodMatcher methodMatcher; public AnnotationMatchingPointcut(Class&lt;? extends Annotation&gt; classAnnotationType, boolean checkInherited) &#123; //切点只针对类级别 this.classFilter = new AnnotationClassFilter(classAnnotationType, checkInherited); this.methodMatcher = MethodMatcher.TRUE; &#125; //...&#125; MethodValidationPostProcessor 中创建了一个切点，过滤类上添加了 @Validated 的 Bean，只要满足此条件，就会根据 MethodValidationInterceptor 生成对应的代理类。嗯，和 @Transactional 的实现原理差不多。 ok，看到这里我就在应用服务实现上添加了 @Validated 注解，那么此时注解生效了吗？哈哈，进度条还没过半呢😂 理论上类上加上 @Validated 注解，应该会生成动态代理类的，竟然没成功进行参数校验，我能想到的原因有二： 1. MethodValidationPostProcessor 没注入到 BeanFactory 中，所以没生成对应的代理类2. MethodValidationInterceptor 对还有其他需要满足的条件，而目前还未满足 这里先剧透一下，答案是 2 🌝 MethodValidationInterceptor 需要满足什么条件竟然答案是2，那这里就先讲一下 MethodValidationInterceptor，MethodValidationPostProcessor 是怎么注册到容器的咱们后面再来讲。 123456789101112131415161718192021222324252627282930313233343536373839ExecutableValidatorpublic class MethodValidationInterceptor implements MethodInterceptor &#123; private final Validator validator; @Override @Nullable public Object invoke(MethodInvocation invocation) throws Throwable &#123; // Standard Bean Validation 1.1 API ExecutableValidator execVal = this.validator.forExecutables(); Method methodToValidate = invocation.getMethod(); Set&lt;ConstraintViolation&lt;Object&gt;&gt; result; //获取类本身的实例（非代理类），请记住这里，这里就是和 Controller 最大的区别 Object target = invocation.getThis(); Assert.state(target != null, \"Target must not be null\"); try &#123; //执行参数校验，校验的是当前类，也就是说校验的是 Bean 对应的类 result = execVal.validateParameters(target, methodToValidate, invocation.getArguments(), groups); &#125; catch (IllegalArgumentException ex) &#123; //doSomeThings &#125; if (!result.isEmpty()) &#123; throw new ConstraintViolationException(result); &#125; //执行方法 Object returnValue = invocation.proceed(); //校验返回值 result = execVal.validateReturnValue(target, methodToValidate, returnValue, groups); if (!result.isEmpty()) &#123; throw new ConstraintViolationException(result); &#125; return returnValue; &#125;&#125; 接下来就要看看 ExecutableValidator.validateParameters 这个方法是如何实现的，为了方便阅读，这里我只保留了部分核心代码。根据包名我们大概也能猜到 ExecutableValidator.validateParameters 是 hibernate-validator 包提供的方法，而 @Validated 注解是由 Spring 提供的，所以不生效也就正常了。接下来我们继续往下走，我这里只贴部分核心的代码，中间的栈路径可以根据以下这个路径往下走： 123456789101112131415161718192021222324252627282930313233343536373839404142434445/** * --&gt; org.hibernate.validator.internal.engine.ValidatorImpl#validateParameters * --&gt; org.hibernate.validator.internal.metadata.BeanMetaDataManager#getBeanMetaData * --&gt; org.hibernate.validator.internal.metadata.BeanMetaDataManagerImpl#createBeanMetaData * --&gt; org.hibernate.validator.internal.metadata.BeanMetaDataManagerImpl#getBeanConfigurationForHierarchy * --&gt; org.hibernate.validator.internal.metadata.provider.MetaDataProvider#getBeanConfiguration * --&gt; org.hibernate.validator.internal.metadata.provider.AnnotationMetaDataProvider#retrieveBeanConfiguration * --&gt; org.hibernate.validator.internal.metadata.provider.AnnotationMetaDataProvider#getFieldMetaData * --&gt; org.hibernate.validator.internal.metadata.provider.AnnotationMetaDataProvider#findPropertyMetaData * --&gt; org.hibernate.validator.internal.metadata.provider.AnnotationMetaDataProvider#findConstraints * --&gt; org.hibernate.validator.internal.metadata.provider.AnnotationMetaDataProvider#findCascadingMetaData * &lt;-- ... * --&gt; org.hibernate.validator.internal.metadata.provider.AnnotationMetaDataProvider#getMethodMetaData * --&gt; org.hibernate.validator.internal.metadata.provider.AnnotationMetaDataProvider#getConstructorMetaData * --&gt; org.hibernate.validator.internal.metadata.provider.AnnotationMetaDataProvider#getClassLevelConstraints * &lt;-- ... * --&gt; org.hibernate.validator.internal.metadata.aggregated.BeanMetaData#hasConstraints * --&gt; org.hibernate.validator.internal.engine.ValidatorImpl#validateParametersInContext * */public class ValidatorImpl implements Validator, ExecutableValidator &#123; @Override public final &lt;T&gt; Set&lt;ConstraintViolation&lt;T&gt;&gt; validateValue(Class&lt;T&gt; beanType, String propertyName, Object value, Class&lt;?&gt;... groups) &#123; Contracts.assertNotNull( beanType, MESSAGES.beanTypeCannotBeNull() ); sanityCheckPropertyPath( propertyName ); sanityCheckGroups( groups ); //获取 bean 及其父类、超类的 BeanMetaData&lt;T&gt; rootBeanMetaData = beanMetaDataManager.getBeanMetaData( beanType ); //判断该 bean 是否有约束 if ( !rootBeanMetaData.hasConstraints() ) &#123; return Collections.emptySet(); &#125; PathImpl propertyPath = PathImpl.createPathFromString( propertyName ); BaseBeanValidationContext&lt;T&gt; validationContext = getValidationContextBuilder().forValidateValue( beanType, rootBeanMetaData, propertyPath ); ValidationOrder validationOrder = determineGroupValidationOrder( groups ); //校验参数 return validateValueInContext(validationContext, value, propertyPath, validationOrder); &#125; //...&#125; 当我调试到 rootBeanMetaData.hasConstraints() 时，判断没有约束，然后就直接返回了没有进行参数校验。我就想说看看是如何判断 Bean 是否有约束的，于是就返回上层进入 beanMetaDataManager.getBeanMetaData 中看，结果发现里面的代码有够复杂的🌚 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public class AnnotationMetaDataProvider implements MetaDataProvider &#123; //获取类上所有的约束条件 private &lt;T&gt; BeanConfiguration&lt;T&gt; retrieveBeanConfiguration(Class&lt;T&gt; beanClass) &#123; //获取字段上的约束条件 Set&lt;ConstrainedElement&gt; constrainedElements = getFieldMetaData( beanClass ); //获取方法上的约束条件（包括参数、返回值） constrainedElements.addAll( getMethodMetaData( beanClass ) ); //获取构造函数 constrainedElements.addAll( getConstructorMetaData( beanClass ) ); //获取类上的约束条件 Set&lt;MetaConstraint&lt;?&gt;&gt; classLevelConstraints = getClassLevelConstraints( beanClass ); if ( !classLevelConstraints.isEmpty() ) &#123; ConstrainedType classLevelMetaData = new ConstrainedType(ConfigurationSource.ANNOTATION, beanClass, classLevelConstraints); constrainedElements.add( classLevelMetaData ); &#125; return new BeanConfiguration&lt;&gt;(ConfigurationSource.ANNOTATION, beanClass, constrainedElements, getDefaultGroupSequence( beanClass ), getDefaultGroupSequenceProvider( beanClass )); &#125; //查找约束注解 protected &lt;A extends Annotation&gt; List&lt;ConstraintDescriptorImpl&lt;?&gt;&gt; findConstraintAnnotations(Constrainable constrainable, A annotation, ConstraintLocationKind type) &#123; //如果包含 \"jdk.internal\" and \"java\" 下的注解，则直接不进行校验 if ( constraintCreationContext.getConstraintHelper().isJdkAnnotation( annotation.annotationType() ) ) &#123; return Collections.emptyList(); &#125; List&lt;Annotation&gt; constraints = newArrayList(); Class&lt;? extends Annotation&gt; annotationType = annotation.annotationType(); //判断是否有约束条件，也就我们经常配置的 @NotNull，@Min 这类注解 if ( constraintCreationContext.getConstraintHelper().isConstraintAnnotation( annotationType ) ) &#123; constraints.add( annotation ); &#125; //这个没用过，暂时跳过 else if ( constraintCreationContext.getConstraintHelper().isMultiValueConstraint( annotationType ) ) &#123; constraints.addAll( constraintCreationContext.getConstraintHelper().getConstraintsFromMultiValueConstraint( annotation ) ); &#125; return constraints.stream() .map( c -&gt; buildConstraintDescriptor( constrainable, c, type ) ) .collect( Collectors.toList() ); &#125; //构建级联元数据构造器，也就是我们常用的 @Valid，在 Bean 中如果我们要对对象属性进行校验， //需要在该属性上添加 @Valid，此处便是如此 private CascadingMetaDataBuilder getCascadingMetaData(JavaBeanAnnotatedElement annotatedElement, Map&lt;TypeVariable&lt;?&gt;, CascadingMetaDataBuilder&gt; containerElementTypesCascadingMetaData) &#123; return CascadingMetaDataBuilder.annotatedObject( annotatedElement.getType(), annotatedElement.isAnnotationPresent( Valid.class ), containerElementTypesCascadingMetaData, getGroupConversions( annotatedElement.getAnnotatedType() ) ); &#125;&#125; 顺着上面的栈路径一直往下走，最终发现最核心的几个方法是 getFieldMetaData、getMethodMetaData、getConstructorMetaData、getClassLevelConstraints，这个几方法都是用于获取约束和级联元数据。那么里面到底是怎么获取约束元数据的呢，咱继续往里钻，可以看到最终调用了 findConstraintAnnotations 获取约束元数据，也就是我们平时用到的 @NotNull，@Min 等注解，通过 getCascadingMetaData 获取级联元数据，也就是 @Valid 注解。看到这，是不是很容易就能想到，知道我加上 @Valid 就能成功校验了呢？ 于是我尝试了一波，果然没问题。嗯~ 长见识了😂。由于时间有限，ValidatorImpl.validateParametersInContext() 方法我就没有深入进去看了。感兴趣的小伙伴可以自行去看看！！🌝 那么 Controller 为啥直接添加 @Validated 或者 @Valid 就可以呢？明白了在应用服务实现，准确的说应该是普通 Bean 中应该怎么配置之 @Validated 和 @Valid 使其生效之后，我就很好奇为啥 Controller 只需要单独在方法上配置 @Validated 或者 @Valid 就能成功校验呢？ 还记得上面通过 IDE 查看应用 @Validated 注解的类时，我们发现了 MethodValidationPostProcessor，还有另外几个类一看就很像 Controller 参数解析相关的类： 我在这几个类上各打了一个断点，最终进入的是 AbstractMessageConverterMethodArgumentResolver。 ok，那就看看他是怎么实现的，这里只贴了很参数校验相关的方法： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556public abstract class AbstractMessageConverterMethodArgumentResolver implements HandlerMethodArgumentResolver &#123; protected void validateIfApplicable(WebDataBinder binder, MethodParameter parameter) &#123; Annotation[] annotations = parameter.getParameterAnnotations(); for (Annotation ann : annotations) &#123; //获取分组信息 Object[] validationHints = ValidationAnnotationUtils.determineValidationHints(ann); if (validationHints != null) &#123; //进行校验 binder.validate(validationHints); break; &#125; &#125; &#125;&#125;public abstract class ValidationAnnotationUtils &#123; @Nullable public static Object[] determineValidationHints(Annotation ann) &#123; Class&lt;? extends Annotation&gt; annotationType = ann.annotationType(); String annotationName = annotationType.getName(); //如果是 @valid 注解直接返回一个空数组 if (\"javax.validation.Valid\".equals(annotationName)) &#123; return EMPTY_OBJECT_ARRAY; &#125; //如果是 @validated 则返回其分组信息 Validated validatedAnn = AnnotationUtils.getAnnotation(ann, Validated.class); if (validatedAnn != null) &#123; Object hints = validatedAnn.value(); return convertValidationHints(hints); &#125; if (annotationType.getSimpleName().startsWith(\"Valid\")) &#123; Object hints = AnnotationUtils.getValue(ann); return convertValidationHints(hints); &#125; return null; &#125;&#125;public class DataBinder implements PropertyEditorRegistry, TypeConverter &#123; public void validate(Object... validationHints) &#123; //此处是关键所在，这里获取的是参数！！！和普通的 Bean 获取到的却是 Bean 本身 Object target = getTarget(); Assert.state(target != null, \"No target to validate\"); BindingResult bindingResult = getBindingResult(); // Call each validator with the same binding result for (Validator validator : getValidators()) &#123; if (!ObjectUtils.isEmpty(validationHints) &amp;&amp; validator instanceof SmartValidator) &#123; ((SmartValidator) validator).validate(target, bindingResult, validationHints); &#125; else if (validator != null) &#123; validator.validate(target, bindingResult); &#125; &#125; &#125;&#125; 可以看到，对于 Controller 不论是直接在参数上加上 @Validated 或者 @Valid 注解，都会进入到校验方法，而且校验的就是参数！！！而 Bean 校验的却是 Bean 本身！！！ MethodValidationPostProcessor 和 AbstractMessageConverterMethodArgumentResolver 是怎么被注册到 BeanFactory 的？明白了 @Validated 的拦截实现的原理后，那么就只剩最后一个问题了，MethodValidationPostProcessor 和 AbstractMessageConverterMethodArgumentResolver 是怎么被注册到 BeanFactory 的。 其实不用看源码大概有也能猜到是 Spring Boot 自动装配的。为了印证一下，我还是贴一下源码： 123456789101112131415161718@Configuration(proxyBeanMethods = false)@ConditionalOnClass(ExecutableValidator.class)@ConditionalOnResource(resources = \"classpath:META-INF/services/javax.validation.spi.ValidationProvider\")@Import(PrimaryDefaultValidatorPostProcessor.class)public class ValidationAutoConfiguration &#123; //... @Bean @ConditionalOnMissingBean public static MethodValidationPostProcessor methodValidationPostProcessor(Environment environment, @Lazy Validator validator, ObjectProvider&lt;MethodValidationExcludeFilter&gt; excludeFilters) &#123; FilteredMethodValidationPostProcessor processor = new FilteredMethodValidationPostProcessor(excludeFilters.orderedStream()); boolean proxyTargetClass = environment.getProperty(\"spring.aop.proxy-target-class\", Boolean.class, true); processor.setProxyTargetClass(proxyTargetClass); processor.setValidator(validator); return processor; &#125;&#125; 另外就是 AbstractMessageConverterMethodArgumentResolver 的几个实现类，均由 RequestMappingHandlerAdapter 实例化，而 RequestMappingHandlerAdapter 大家知道有 WebMvcAutoConfiguration 自动装配，时间原因，这就不看了。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public class RequestMappingHandlerAdapter extends AbstractHandlerMethodAdapter implements BeanFactoryAware, InitializingBean &#123; private List&lt;HandlerMethodArgumentResolver&gt; getDefaultArgumentResolvers() &#123; List&lt;HandlerMethodArgumentResolver&gt; resolvers = new ArrayList&lt;&gt;(30); // Annotation-based argument resolution resolvers.add(new RequestParamMethodArgumentResolver(getBeanFactory(), false)); resolvers.add(new RequestParamMapMethodArgumentResolver()); resolvers.add(new PathVariableMethodArgumentResolver()); resolvers.add(new PathVariableMapMethodArgumentResolver()); resolvers.add(new MatrixVariableMethodArgumentResolver()); resolvers.add(new MatrixVariableMapMethodArgumentResolver()); resolvers.add(new ServletModelAttributeMethodProcessor(false)); resolvers.add(new RequestResponseBodyMethodProcessor(getMessageConverters(), this.requestResponseBodyAdvice)); resolvers.add(new RequestPartMethodArgumentResolver(getMessageConverters(), this.requestResponseBodyAdvice)); resolvers.add(new RequestHeaderMethodArgumentResolver(getBeanFactory())); resolvers.add(new RequestHeaderMapMethodArgumentResolver()); resolvers.add(new ServletCookieValueMethodArgumentResolver(getBeanFactory())); resolvers.add(new ExpressionValueMethodArgumentResolver(getBeanFactory())); resolvers.add(new SessionAttributeMethodArgumentResolver()); resolvers.add(new RequestAttributeMethodArgumentResolver()); // Type-based argument resolution resolvers.add(new ServletRequestMethodArgumentResolver()); resolvers.add(new ServletResponseMethodArgumentResolver()); resolvers.add(new HttpEntityMethodProcessor(getMessageConverters(), this.requestResponseBodyAdvice)); resolvers.add(new RedirectAttributesMethodArgumentResolver()); resolvers.add(new ModelMethodProcessor()); resolvers.add(new MapMethodProcessor()); resolvers.add(new ErrorsMethodArgumentResolver()); resolvers.add(new SessionStatusMethodArgumentResolver()); resolvers.add(new UriComponentsBuilderMethodArgumentResolver()); if (KotlinDetector.isKotlinPresent()) &#123; resolvers.add(new ContinuationHandlerMethodArgumentResolver()); &#125; // Custom arguments if (getCustomArgumentResolvers() != null) &#123; resolvers.addAll(getCustomArgumentResolvers()); &#125; // Catch-all resolvers.add(new PrincipalMethodArgumentResolver()); resolvers.add(new RequestParamMethodArgumentResolver(getBeanFactory(), true)); resolvers.add(new ServletModelAttributeMethodProcessor(true)); return resolvers; &#125;&#125; 小结1、在普通 Bean 中如果要通过注解的方式使用 hibernate-validator 进行校验的话，需要在类上添加 @Validated 注解，同时在方法上添加 @Valid 注解。或者也可以直接使用 @NotNull 等注解。 2、普通 Bean 使用 @Validated 是通过动态代理完成的。具体的拦截器便是他 MethodValidationInterceptor。 3、Controller 层之所以能 @Validated 和 @Valid 二选一，是因为校验的是参数本身，而普通 Bean 校验的是 Bean 本身。 4、至此，相信大家就不会没配置好 @Validated 导致失效了。","categories":[],"tags":[{"name":"spring","slug":"spring","permalink":"http://example.com/tags/spring/"}]},{"title":"kafka 消费者高 cpu 问题排查","slug":"kafka-消费者高-cpu-问题排查","date":"2023-04-14T15:31:22.000Z","updated":"2023-04-14T15:48:38.289Z","comments":true,"path":"2023/04/14/kafka-消费者高-cpu-问题排查/","link":"","permalink":"http://example.com/2023/04/14/kafka-%E6%B6%88%E8%B4%B9%E8%80%85%E9%AB%98-cpu-%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5/","excerpt":"","text":"今天本来打算愉快的划水，运维小哥突然找我说测试环境应用 cpu 一直居高不下，我一看告警还真是… cpu 高问题排查思路首先还是老套路： 先查看 cpu 高的线程是哪些 1top -Hp &lt;pid&gt; 查看线程的堆栈信息 12345//将线程 id 转换为 16 进制printf '%x\\n' &lt;tid&gt;//获取线程号后 50 行堆栈信息jstack &lt;pid&gt; | grep &lt;tid&gt; -A 50 这里我就直接用线程名称去查了。 看堆栈信息定位到是 kafka 消费者消费消息，导致 cpu 居高不下，正常情况下 kafka 消费者 cpu 飚高都是有大量的消息，我第一个感觉就是测试在进行压测，结果一看，打脸了🤔。 可以看到，lag 是 0 或者负数，我又刷新了几次基本上没有多少消息，这里留个心眼，后面我们在好好唠唠。 那么问题就来了，没有消息为啥消费者 cpu 会飚高… 突然灵机一动，会不会是消费者数太多了，导致循环去调用 poll 方法，造成整个节点 cpu 飚高。然后就屁颠屁颠的把所有主题的消费者数调小了，然鹅想想很美好，现实很骨感… 重启后节点的 cpu 依然居高不下。 遇到不懂就问度娘在网上逛了一圈，看到许多相似的场景，各种操作都试了一遍，还是没什么用🙃，kafka 的 github 仓库我也去逛了一圈，发现也有很多 cpu 高得场景，大多数都是建议升级客户端版本，忘了说我司目前用的还是 0.11.2，总之逛了一圈没有起到太大的帮助。 接着就是一波虾皮操作，显示生成了火焰图，看看 consumer poll 到底为啥一直占用 cpu，下面是一张火焰图： 虽然 poll 方法占用 cpu 耗时很长，但是仔细看又觉得没啥问题，是正常的在处理网络请求，这个时候我甚至一度怀疑是 kafka 客户端的 bug 😂。 有耐心问题迟早能解决还记的我们之前提了一嘴那张截图吗，没错就是下面这张 图中 lag 出现负数，其实 lag 出现负数还是很常见的，但问题就出在我排查了这么久图中的 lag 好像没变化过，而且一直是负数，那就很值得注意了。 我们还是先说说 lag 是怎么计算的 1lag = HW - consumerOffset HW: 高水位，通常等于所有 ISR 中最小的 LEO，详细的可以看看大佬的博客 consumerOffset: 表示消费者提交的消费位移 那么 lag 为啥会出现负数呢，由于我本身并未看过源码，所以从网上找了一个我认为比较是能说的通的解释: Producer 的 offset 是通过 JMX 轮询获得的，Consumer 的 offset 是从 kafka 内的 __consumer_offsets 的 topic 中直接读取到的，很明显轮询获取 offset 比 直接从 topic 拿 offset 慢一点，也就可能会出现 Lag 计算后为负数的情况。 OK，回到正题，lag 长时间是负数说明 consumerOffset 一直大于 HW，那么出现这个问题的原因大概率是 HW 一直不更新，因为 HW 只要更新其实 lag 很快就能变回 0。那么 HW 是什么时候更新的呢，其实是 Follower 副本同步 Leader 副本数据时，Leader 副本会对比 Follower 拉取数据的 offset 和 Leader 自身的 LEO 去更新 HW，所以通常 HW 需要 Follower 多同步一轮才会更新。 那么 HW 不更新，只能说明 Follower 没有去同步数据，想到这，我立马去看了下消费组的副本状态，发现有一个 broker 所有的分区副本都不在 ISR 中。那么基本上确定这个 broker 是出现问题了，但是这和我消费者 cpu 高有什么关系呢？ 这时运维小哥告诉我，poll 平均每 3ms 就请求一次，导致 cpu 飚高。纳尼？？？我的 poll timeout 明明是 100ms，怎么 3ms 一次呢，这明显有问题呀，运维小哥发了一下抓包的截图给我： kafka broker response 中提示 Not Leader For Partition，这不就和上面的猜想对上了吗，看看 chatgpt 给出的解释: 至此问题就排查了差不多了，那么接下来就是解决。由于是在测试环境发现的，解决方式也很粗暴，就是直接把 topic 直接删除了，然后重新创建。 小结 遇到涉及网络相关的问题，可以抓个包瞧瞧，说不定思路一下就打开了。 如果实在生产环境遇到这类问题，那么该怎么处理 broker 呢，这个得好好琢磨琢磨，目前思路是从 controller 下手。","categories":[],"tags":[{"name":"kafka","slug":"kafka","permalink":"http://example.com/tags/kafka/"}]},{"title":"wireshark 抓包 java应用中的 https 请求","slug":"wireshark-抓包-java应用中的-https-请求","date":"2023-04-03T07:08:41.000Z","updated":"2023-04-03T07:12:39.504Z","comments":true,"path":"2023/04/03/wireshark-抓包-java应用中的-https-请求/","link":"","permalink":"http://example.com/2023/04/03/wireshark-%E6%8A%93%E5%8C%85-java%E5%BA%94%E7%94%A8%E4%B8%AD%E7%9A%84-https-%E8%AF%B7%E6%B1%82/","excerpt":"","text":"最近生产中请求第三方接口的服务频繁告警，接口响应过慢，我们这边使用的 httpclient 连接池，各项配置看起来都没太大的问题，于是就想着说抓包看看是否有网络层面的问题还是的确是第三方接口慢。 通过 jsslkeylog 获取 sslkeylogwireshark 中 https 显示密文的样子有用过 wireshark 抓包 https 的大佬应该都知道，https 是有加密的，直接用 wireshark 抓包展示的全都是密文，如下图：可以看到，具体的 https 请求数据都被加密了。 如何让 https 在 wireshark 显示明文wireshark 中解密 https 请求的方式有多种，这里使用的方式是获取 https 请求时的 sslkeylog，使用到了一个 javaagent 工具 jsslkeylog，通过修改字节码达到发送 https 请求时将使用到的 sslkeylog 写入到本地磁盘的效果。具体流程也很简单：1、下载 jsslkeylog jar 包2、启动命令中加入 -javaagent:/path_to_jar/jSSLKeyLog.jar=/path_to_log/sslkeylog.log3、启动应用发起 https 请求4、之后应该就会在配置的 /path_to_log 中看到对应的 sslkeylog5、之后将 log 配置到 wireshark 中，prfferences -&gt; protocols -&gt; tls配置完成之后，就能看到原本的密文已经变成明文了，之后就能愉快的分析了🌝","categories":[],"tags":[{"name":"java","slug":"java","permalink":"http://example.com/tags/java/"},{"name":"计算机网络","slug":"计算机网络","permalink":"http://example.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}]},{"title":"k8s 搭建","slug":"k8s-搭建","date":"2023-03-31T15:45:37.000Z","updated":"2023-03-31T15:46:40.276Z","comments":true,"path":"2023/03/31/k8s-搭建/","link":"","permalink":"http://example.com/2023/03/31/k8s-%E6%90%AD%E5%BB%BA/","excerpt":"","text":"k8s搭建说明本文系搭建 kubernetes v1.21.3 版本集群笔记，使用三台虚拟机作为 CentOS7.9 系统测试机，安装 kubeadm、kubelet、kubectl 均使用 yum 安装，网络组件选用的是 flannel。 环境准备部署集群没有特殊说明均使用 root 用户执行命令。 2.1 硬件信息 ip hostname mem disk explain 192.168.85.2 192.168.85.2 2G 40GB k8s 控制平面节点 192.168.85.3 192.168.85.3 2G 40GB k8s 执行节点1 192.168.85.4 192.168.85.4 2G 40GB k8s 执行节点2 2.2 软件信息 12345software versionCentOS CentOS Linux release 7.9.2009 (Core)Kubernetes 1.21.3Docker 20.10.8Kernel 5.4.138-1.el7.elrepo.x86_64 2.3 禁用 swapswap 仅当内存不够时会使用硬盘块充当额外内存，硬盘的 io 较内存差距极大，禁用 swap 以提高性能各节点均需执行： 123swapoff -a cp /etc/fstab /etc/fstab.bakcat /etc/fstab.bak | grep -v swap &gt; /etc/fstab 2.4 关闭 SELinux 关闭 SELinux，否则 kubelet 挂载目录时可能报错 Permission denied，可以设置为 permissive 或 disabled，permissive 会提示 warn 信息各节点均需执行： 12setenforce 0 sed -i 's/^SELINUX=.*/SELINUX=disabled/' /etc/selinux/config 2.5 设置时区、同步时间 12timedatectl set-timezone Asia/Shanghai systemctl enable --now chronyd 查看同步状态： 1timedatectl status 2.6 关闭防火墙 12systemctl stop firewalldsystemctl disable firewalld 安装必要依赖1yum install -y yum-utils device-mapper-persistent-data lvm2 3.1 添加 aliyun docker-ce yum 源 1yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo 重建 yum 缓存 1yum makecache fast 3.2 安装 Docker 查看可用 docker 版本 1yum list docker-ce.x86_64 --showduplicates | sort -r ==安装指定版本 Docker== yum install -y docker-ce-20.10.14-3.el7 这里以安装 20.10.14 版本举例，注意版本号不包含 : 与之前的数字。 3.3 确保网络模块开机自动加载 12lsmod | grep overlay lsmod | grep br_netfilter 若上面命令无返回值输出或提示文件不存在，需执行以下命令： 123456cat &gt; /etc/modules-load.d/docker.conf &lt;&lt;EOF overlay br_netfilter EOFmodprobe overlay modprobe br_netfilter 3.4 使桥接流量对 iptables 可见各个节点均需执行： 12345cat &gt; /etc/sysctl.d/k8s.conf &lt;&lt;EOF net.bridge.bridge-nf-call-ip6tables = 1net.bridge.bridge-nf-call-iptables = 1EOFsysctl --system 验证是否生效，均返回 1 即正确。 12sysctl -n net.bridge.bridge-nf-call-iptables sysctl -n net.bridge.bridge-nf-call-ip6tables 3.5 配置 Docker 1mkdir /etc/docker 修改 cgroup 驱动为 systemd [k8s官方推荐]、限制容器日志量、修改存储类型，最后的 docker 家目录可修改： 123456789101112131415cat &gt; /etc/docker/daemon.json &lt;&lt;EOF&#123; \"exec-opts\": [\"native.cgroupdriver=systemd\"], \"log-driver\": \"json-file\", \"log-opts\": &#123; \"max-size\": \"100m\" &#125;, \"storage-driver\": \"overlay2\", \"storage-opts\": [ \"overlay2.override_kernel_check=true\" ], \"registry-mirrors\": [\"https://gp8745ui.mirror.aliyuncs.com\"], \"data-root\": \"/data/docker\"&#125;EOF 服务脚本第 13 行修改： 123vim /lib/systemd/system/docker.serviceExecStart=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock --default-ulimit core=0:0systemctl daemon-reload 添加开机自启，立即启动： 1systemctl enable --now docker 3.6 验证 Docker 是否正常 查看docker信息，判断是否与配置一致 部署 Kubernetes 集群如未说明，各节点均需执行如下步骤： 4.1 添加 kubernetes 源 123456789cat &gt; /etc/yum.repos.d/kubernetes.repo &lt;&lt;EOF[kubernetes]name=Kubernetesbaseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/enabled=1gpgcheck=1repo_gpgcheck=1gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpgEOF 重建yum缓存，输入y添加证书认证 1yum makecache fast 4.2 安装 kubeadm、kubelet、kubectl各节点均需安装 kubeadm、kubelet 12345yum list docker-ce.x86_64 --showduplicates | sort -rversion=1.21.3-0yum install -y kubelet-v1.21.0 kubeadm-v1.21.0 kubectl-v1.21.0systemctl enable kubelet --now 4.3 配置自动补全命令 安装 bash 自动补全插件 1yum install bash-completion -y 设置 kubectl 与 kubeadm 命令补全，下次 login 生效 12kubectl completion bash &gt;/etc/bash_completion.d/kubectlkubeadm completion bash &gt; /etc/bash_completion.d/kubeadm 4.4 为 Docker 设定使用的代理服务(暂跳过该步骤，由阿里云镜像解决)Kubeadm 部署 Kubernetes 集群的过程中，默认使用 Google 的 Registry 服务 k8s.gcr.io 上的镜像，例如k8s.grc.io/kube-apiserver 等，但国内无法访问到该服务。必要时，可自行设置合适的代理来获取相关镜像，或者从 Dockerhub 上下载镜像至本地后自行对镜像打标签。 这里简单说明一下设置代理服务的方法。编辑 /lib/systemd/system/docker.service 文件，在 [Service] 配置段中添加类似如下内容，其中的 PROXY_SERVER_IP 和 PROXY_PORT 要按照实际情况修改。 123Environment=\"HTTP_PROXY=http://$PROXY_SERVER_IP:$PROXY_PORT\"Environment=\"HTTPS_PROXY=https://$PROXY_SERVER_IP:$PROXY_PORT\"Environment=\"NO_PROXY=192.168.4.0/24\" 配置完成后需要重载 systemd，并重新启动 docker 服务： 12systemctl daemon-reloadsystemctl restart docker.service 需要特别说明的是，由 kubeadm 部署的 Kubernetes 集群上，集群核心组件 kube-apiserver、kube-controller-manager、kube-scheduler 和 etcd 等均会以静态 Pod 的形式运行，它们所依赖的镜像文件默认来自于 k8s.gcr.io 这一 Registry 服务之上。但我们无法直接访问该服务，常用的解决办法有如下两种，本示例将选择使用更易于使用的前一种方式： 使用能够到达该服务的代理服务使用国内的镜像服务器上的服务，例如 gcr.azk8s.cn/google_containers 和 registry.aliyuncs.com/google_containers 等（经测试，v1.22.0 版本已停用）4.5 查看指定 k8s 版本需要哪些镜像 123456789kubeadm config images list --kubernetes-version v1.21.0k8s.gcr.io/kube-apiserver:v1.21.0k8s.gcr.io/kube-controller-manager:v1.21.0k8s.gcr.io/kube-scheduler:v1.21.0k8s.gcr.io/kube-proxy:v1.21.0k8s.gcr.io/pause:3.4.1k8s.gcr.io/etcd:3.4.13-0k8s.gcr.io/coredns/coredns:v1.8.0 4.6 拉取镜像 1vim pullimages.sh 1234567891011121314151617181920212223#!/bin/bash# pull images ver=v1.21.0registry=registry.cn-hangzhou.aliyuncs.com/google_containersimages=`kubeadm config images list --kubernetes-version=$ver |awk -F '/' '&#123;print $2&#125;'` for image in $imagesdoif [ $image != coredns ];then docker pull $&#123;registry&#125;/$image if [ $? -eq 0 ];then docker tag $&#123;registry&#125;/$image k8s.gcr.io/$image docker rmi $&#123;registry&#125;/$image else echo \"ERROR: 下载镜像报错，$image\" fielse docker pull coredns/coredns:1.8.0 docker tag coredns/coredns:1.8.0 k8s.gcr.io/coredns/coredns:v1.8.0 docker rmi coredns/coredns:1.8.0fidone 4.7 修改 kubelet 配置默认 cgroup driver 123456mkdir /var/lib/kubeletcat &gt; /var/lib/kubelet/config.yaml &lt;&lt;EOFapiVersion: kubelet.config.k8s.io/v1beta1kind: KubeletConfigurationcgroupDriver: systemdEOF 4.8 初始化 master 节点仅 192.168.85.2 节点需要执行此步骤。 4.8.1 生成 kubeadm 初始化配置文件[可选] 仅当需自定义初始化配置时用。 1kubeadm config print init-defaults &gt; kubeadm-config.yaml 修改配置文件： 12localAPIEndpoint: advertiseAddress: 1.2.3.4 替换为： 1234localAPIEndpoint: advertiseAddress: 192.168.85.2 name: 192.168.85.2kubernetesVersion: 1.21.0 123networking: dnsDomain: cluster.local serviceSubnet: 10.96.0.0/12 替换为： 1234kubernetesVersion: 1.21.0networking: podSubnet: \"10.244.0.0/16\" serviceSubnet: 10.96.0.0/12 4.8.2 测试环境是否正常 1kubeadm init phase preflight 4.8.3 初始化 master10.244.0.0/16 是 flannel 固定使用的 IP 段，设置取决于网络组件要求。 1kubeadm init --config=kubeadm-config.yaml --ignore-preflight-errors=2 --upload-certs | tee kubeadm-init.log 4.8.4 为日常使用集群的用户添加 kubectl 使用权限 123456su - iuskyemkdir -p $HOME/.kubesudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/admin.confsudo chown $(id -u):$(id -g) $HOME/.kube/admin.confecho \"export KUBECONFIG=$HOME/.kube/admin.conf\" &gt;&gt; ~/.bashrcexit 4.8.5 配置 master 认证 12echo 'export KUBECONFIG=/etc/kubernetes/admin.conf' &gt;&gt; /etc/profile . /etc/profile 如果不配置这个，会提示如下输出：The connection to the server localhost:8080 was refused - did you specify the right host or port?此时 master 节点已经初始化成功，但是还未安装网络组件，还无法与其他节点通讯。 4.8.6 安装网络组件以 flannel 为例： 1234curl -o kube-flannel.yml https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.ymlkubectl apply -f kube-flannel.yml # 这里下载镜像非常慢，我还是先手动拉下来吧，不行就多试几次docker pull quay.io/coreos/flannel:v0.14.0kubectl apply -f kube-flannel.yml 4.8.7 查看 192.168.85.2 节点状态 123456kubectl get nodesNAME STATUS ROLES AGE VERSION192.168.85.2 Ready control-plane,master 15d v1.21.0192.168.85.3 Ready &lt;none&gt; 15d v1.21.0192.168.85.4 Ready &lt;none&gt; 15d v1.21.0 如果 STATUS 提示 NotReady，可以通过 kubectl describe node 192.168.85.2 查看具体的描述信息，性能差的服务器到达 Ready 状态时间会长些。 4.9 初始化 node 节点并加入集群4.9.1 获取加入 kubernetes 的命令访问 192.168.85.2 输入创建新 token 命令： 1kubeadm token create --print-join-command 同时输出加入集群的命令： 1kubeadm join 192.168.85.2:6443 --token zukr14.dg1pxt9k9gndzqkl --discovery-token-ca-cert-hash sha256:0b57947ccd86cea8b7af2490fde858f3870e63bf35bbb0a567c702029376e9e5 这个 token 也可以使用上述 master 上执行的初始化输出结果。 4.9.2 在 node 节点上执行加入集群的命令 1kubeadm join 192.168.85.2:6443 --token zukr14.dg1pxt9k9gndzqkl --discovery-token-ca-cert-hash sha256:0b57947ccd86cea8b7af2490fde858f3870e63bf35bbb0a567c702029376e9e5 4.10 查看集群节点状态 123456kubectl get nodesNAME STATUS ROLES AGE VERSION192.168.85.2 Ready control-plane,master 15d v1.21.0192.168.85.3 Ready &lt;none&gt; 15d v1.21.0192.168.85.4 Ready &lt;none&gt; 15d v1.21.0 4.11 部署 Dashboard4.11.1 部署 1curl -o recommended.yaml https://raw.githubusercontent.com/kubernetes/dashboard/v2.3.1/aio/deploy/recommended.yaml 默认 Dashboard 只能集群内部访问，修改 Service 为 NodePort 类型，暴露到外部： 12345678910111213141516vi recommended.yamlkind: ServiceapiVersion: v1metadata: labels: k8s-app: kubernetes-dashboard name: kubernetes-dashboard namespace: kubernetes-dashboardspec: ports: - port: 443 targetPort: 8443 nodePort: 30001 type: NodePort selector: k8s-app: kubernetes-dashboard 12345678910111213kubectl apply -f recommended.yaml # 这里下载镜像非常慢，我还是先手动拉下来吧，不行就多试几次docker pull kubernetesui/dashboard:v2.3.1docker pull kubernetesui/metrics-scraper:v1.0.6kubectl apply -f recommended.yamlkubectl get pods,svc -n kubernetes-dashboardNAME READY STATUS RESTARTS AGEpod/dashboard-metrics-scraper-856586f554-nb68k 0/1 ContainerCreating 0 52spod/kubernetes-dashboard-67484c44f6-shtz7 0/1 ContainerCreating 0 52sNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEservice/dashboard-metrics-scraper ClusterIP 10.96.188.208 &lt;none&gt; 8000/TCP 52sservice/kubernetes-dashboard NodePort 10.97.164.152 &lt;none&gt; 443:30001/TCP 53s 查看状态正在创建容器中，稍后再次查看： 123456NAME READY STATUS RESTARTS AGEpod/dashboard-metrics-scraper-856586f554-nb68k 1/1 Running 0 2m11spod/kubernetes-dashboard-67484c44f6-shtz7 1/1 Running 0 2m11sNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEservice/dashboard-metrics-scraper ClusterIP 10.96.188.208 &lt;none&gt; 8000/TCP 2m11sservice/kubernetes-dashboard NodePort 10.97.164.152 &lt;none&gt; 443:30001/TCP 2m12s 访问地址：https://NodeIP:30001；使用 Firefox 浏览器，Chrome 浏览器打不开不信任 SSL 证书的网站。 创建 service account 并绑定默认 cluster-admin 管理员集群角色： 123kubectl create serviceaccount dashboard-admin -n kube-systemkubectl create clusterrolebinding dashboard-admin --clusterrole=cluster-admin --serviceaccount=kube-system:dashboard-adminkubectl describe secrets -n kube-system $(kubectl -n kube-system get secret | awk '/dashboard-admin/&#123;print $1&#125;') 这里需要注意粘贴的时候有可能被换行，如果被换行，可在记事本中设置为一行。 使用输出的 token 登录 Dashboard。 问题解决1、dial tcp 10.96.0.1:443: connect: no route to host 123456systemctl stop dockersystemctl stop kubeletiptables --flushiptables -tnat --flushsystemctl start kubeletsystemctl start docker 2、failed to delegate add: failed to set bridge addr: “cni0“ already has an IP address different from 1 1https://blog.csdn.net/weixin_42562106/article/details/123749291 3、failed to add vxlanRoute (10.244.0.0/24 -&gt; 10.244.0.0): network is down 1234ip link delete flannel.1systemctl restart networkkubectl delete -f kube-flannel.ymlkubectl apply -f kube-flannel.yml 4、Get http://10.244.0.3:8181/ready: dial tcp 10.244.0.3:8181: connect: connection refused 12#重新corednskubectl -n kube-system rollout restart deployment/coredns 以上几个问题遇到可以先尝试重启所有的机器，如果不行在通过上述方案解决 参考：https://www.iuskye.com/2021/08/10/k8s-kubeadm-1213.html","categories":[],"tags":[{"name":"运维","slug":"运维","permalink":"http://example.com/tags/%E8%BF%90%E7%BB%B4/"},{"name":"k8s","slug":"k8s","permalink":"http://example.com/tags/k8s/"}]},{"title":"redisson3.15.2 公平锁任务丢失","slug":"redisson3.15.2 公平锁任务丢失","date":"2023-03-31T15:22:45.000Z","updated":"2023-03-31T15:37:33.829Z","comments":true,"path":"2023/03/31/redisson3.15.2 公平锁任务丢失/","link":"","permalink":"http://example.com/2023/03/31/redisson3.15.2%20%E5%85%AC%E5%B9%B3%E9%94%81%E4%BB%BB%E5%8A%A1%E4%B8%A2%E5%A4%B1/","excerpt":"","text":"场景： 线索流转改成 redisson 公平锁，任务耗时长，导致部分任务丢失。 一、redisson 公平锁实现1、redis 中的 K/V12345678list: redisson_lock_queue:&#123;test&#125; elem: UUID:threadIdzset: redisson_lock_timeout:&#123;key&#125; elem: UUID:threadId score: timeout = ttl + 线程等待时间(5*60000ms) + 当前时间戳hset: key hashKey: UUID:threadId hashVal: 1 2、上锁流程（这里就不放源码了，感兴趣可以自己看看） org.redisson.RedissonFairLock#tryLockInnerAsync 清除 redisson_lock_timeout:{key} 中 score 小于当前时间戳的elem，同时清除对应 redisson_lock_queue:{test} 中的 elem 如果当前没有线程占用锁，则上锁 (ttl = watchdogtimeout)，同时redisson_lock_timeout:{key} 中所有的 score - 线程等待时间(5*60000ms) 如果存在锁，且是被当前线程占用的，则 hashVal 加一 如果存在锁，且不是被当前线程占用的，同时已经加入过等待队列，则返回当前线程在队列中的 ttl 如果存在锁，且不是被当前线程占用的，并且未加入等待队列，则加入等待队列，timeout= ttl + 线程等待时间(5*60000ms) + 当前时间戳，ttl 为队列中最后一个元素的 timeout - current 或者 锁的超时时间 3、订阅 redisson_lock__channel:{fairLock}:UUID:threadId此处阻塞线程，直到消息队列中有消息发送为止 4、解锁流程 清除 redisson_lock_timeout:{key} 中 score 小于当前时间戳的elem，同时清除对应 redisson_lock_queue:{test} 中的 elem 判断锁是否存在，如果不存在则说明锁已经被释放了，判断等待队列中是否有elem，有的话取出第一个 publish message 如果锁存在，且非本线程持有，则直接返回 null 如果所存在，且是当前线程持有，并且获取所次数大于 1，则 hashVal减一，更新锁超时时间 如果所存在，且是当前线程持有，释放锁，判断等待队列中是否有elem，有的话取出第一个 publish message 5、获取到锁之后，取消订阅 redisson_lock__channel:{fairLock}:UUID:threadId 二、问题分析1、由于测试环境第三方鉴权接口较慢，每分配一条线索需要3-4s 2、存量线索有 1500+ 条，每 200 条作为一个任务，总共拆分 8 个任务，每个任务需要执行 200*3 = 600+ s 3、redisson 公平锁线程等待时间 (5*60000ms)，也就是说单个任务执行完至少会有一个任务过期，在 unlock 或者 lock 操作是会先清除过期任务 4、由于获取不到锁，线程会订阅 redisson_lock__channel:{fairLock}:UUID:threadId，阻塞知道接收到消息，又由于等待队列里的线程被清了，这个消息队列永远不会收到消息，所以线程一直阻塞，且任务无法执行，资源被占用。 5、代码模拟： 1234567891011121314151617public static void main(String[] args) &#123; Config config = new Config(); config.useSingleServer().setAddress(\"redis://127.0.0.1:6379\"); Redisson redissonClient = (Redisson) Redisson.create(config); IntStream.range(0, 10).forEach(i -&gt; &#123; new Thread(() -&gt; &#123; //RedissonFairLock lock = (RedissonFairLock) redissonClient.getFairLock(\"test\"); RedissonFairLock lock = new RedissonFairLock(redissonClient.getCommandExecutor(), \"test\", 2000); lock.lock(); //最终输出次数小于10 System.out.println(i); ThreadUtil.sleep(10000); lock.unlock(); &#125;).start(); &#125;); &#125; 参考: Redisson分布式锁之公平锁原理","categories":[{"name":"redisson","slug":"redisson","permalink":"http://example.com/categories/redisson/"}],"tags":[{"name":"redisson","slug":"redisson","permalink":"http://example.com/tags/redisson/"},{"name":"框架","slug":"框架","permalink":"http://example.com/tags/%E6%A1%86%E6%9E%B6/"}]},{"title":"apollo 集群架构","slug":"apollo-集群架构","date":"2023-03-25T18:25:23.000Z","updated":"2023-03-31T15:44:48.277Z","comments":true,"path":"2023/03/26/apollo-集群架构/","link":"","permalink":"http://example.com/2023/03/26/apollo-%E9%9B%86%E7%BE%A4%E6%9E%B6%E6%9E%84/","excerpt":"","text":"apollo 集群架构apollo 组成结构apollo 集群主要有三个部分组成，config-service，admin-service，portal config-service: 主要为应用客户端提供服务，包括配置的读取、推送等功能，config-service 内置 eureka，已提供 admin-service, portal 的服务发现、服务注册 admin-service: 主要为 apollo-portal 提供服务，包括应用配置管理、发布等功能 portal: 是 apollo 提供的服务配置前端页面 apollo 部署方案这个官网提供的高可用双环境架构，更多的架构方案可参考 docker-compose 部署 apollo 集群 执行 sql 脚本，生成 apollo 需要的 db 表 编写 docker-compose 文件，本次只搭建开发环境模拟单机单环境，config-service，admin-service，portal 都各自部署一个容器 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556version: '2'networks: net:services: #开发环境configService，eureka apollo-configservice-dev: image: apolloconfig/apollo-configservice container_name: configservice-dev ports: - 8080:8080 environment: - SPRING_DATASOURCE_URL=jdbc:mysql://192.168.0.103:3306/ApolloConfigDB?characterEncoding=utf8 - SPRING_DATASOURCE_USERNAME=root - SPRING_DATASOURCE_PASSWORD=123456 - eureka.instance.ip-address=192.168.0.103 networks: - net apollo-adminservice-dev: image: apolloconfig/apollo-adminservice container_name: adminservice-dev ports: - 8090:8090 environment: - SPRING_DATASOURCE_URL=jdbc:mysql://192.168.0.103:3306/ApolloConfigDB?characterEncoding=utf8 - SPRING_DATASOURCE_USERNAME=root - SPRING_DATASOURCE_PASSWORD=123456 #这里需要配置开环环境的configService - eureka.service.url=http://configservice-dev:8080/eureka/ depends_on: - apollo-configservice-dev networks: - net apollo-portal: image: apolloconfig/apollo-portal container_name: apollo-portal ports: - 8070:8070 environment: - SPRING_DATASOURCE_URL=jdbc:mysql://192.168.0.103:3306/ApolloPortalDB?characterEncoding=utf8 - SPRING_DATASOURCE_USERNAME=root - SPRING_DATASOURCE_PASSWORD=123456 - spring.profiles.active=auth - APOLLO_PORTAL_ENVS=dev,fat,pre,gray,pro - DEV_META=http://configservice-dev:8080 # 以下这些暂时使用开发环境的 - FAT_META=http://configservice-dev:8080 - PRE_META=http://configservice-dev:8080 - GRAY_META=http://configservice-dev:8080 - PRO_META=http://configservice-dev:8080 depends_on: - apollo-adminservice-dev networks: - net","categories":[],"tags":[{"name":"apollo","slug":"apollo","permalink":"http://example.com/tags/apollo/"},{"name":"运维","slug":"运维","permalink":"http://example.com/tags/%E8%BF%90%E7%BB%B4/"}]},{"title":"consul 集群搭建及注意事项","slug":"consul-集群搭建及注意事项","date":"2023-03-25T17:16:50.000Z","updated":"2023-03-31T15:45:02.909Z","comments":true,"path":"2023/03/26/consul-集群搭建及注意事项/","link":"","permalink":"http://example.com/2023/03/26/consul-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA%E5%8F%8A%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9/","excerpt":"","text":"集群搭建本次利用 docker 搭建 consul 集群，利用 docker-compose 统一管理 集群包含三个 server agent: node1、node2、node3 集群包含两个 client agent: node4、node5，client agent 提供 ui **1、下载 docker 镜像 ** 1docker pull docker 2、编辑 docker-compose.yml 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253version: '2'networks: byfn:services: consul1: image: consul container_name: node1 command: agent -server -bootstrap-expect=3 -node=node1 -bind=0.0.0.0 -client=0.0.0.0 -datacenter=dc1 networks: - byfn consul2: image: consul container_name: node2 command: agent -server -retry-join=node1 -node=node2 -bind=0.0.0.0 -client=0.0.0.0 -datacenter=dc1 depends_on: - consul1 networks: - byfn consul3: image: consul container_name: node3 command: agent -server -retry-join=node1 -node=node3 -bind=0.0.0.0 -client=0.0.0.0 -datacenter=dc1 depends_on: - consul1 networks: - byfn consul4: image: consul container_name: node4 command: agent -retry-join=node1 -node=ndoe4 -bind=0.0.0.0 -client=0.0.0.0 -datacenter=dc1 -ui ports: - 8500:8500 depends_on: - consul2 - consul3 networks: - byfn consul5: image: consul container_name: node5 command: agent -retry-join=node1 -node=ndoe5 -bind=0.0.0.0 -client=0.0.0.0 -datacenter=dc1 -ui ports: - 8501:8500 depends_on: - consul2 - consul3 networks: - byfn 命令行参数-server：表示当前使用的 server 模式；如果没有指定，则表示是 client 模式。 -node：指定当前节点在集群中的名称。 -config-dir：指定配置文件路径，定义服务的；路径下面的所有 .json 结尾的文件都被访问；缺省值为：/consul/config。 -data-dir： consul 存储数据的目录；缺省值为：/consul/data。 -datacenter：数据中心名称，缺省值为 dc1。 -ui：使用 consul 自带的 web UI 界面 。 -join：加入到已有的集群中。 -retry-join：与 -join 类似，但允许重试连接，直到连接成功。一旦成功加入成员列表中的成员，它将永远不会尝试再次加入。然后，代理商将仅通过八卦维持其会员资格。允许配置多个 -retry-join，然后节点会按照顺序加入和重试，直到第一个成功。 -enable-script-checks： 检查服务是否处于活动状态，类似开启心跳。 -advertise：通告地址用于更改我们向集群中其他节点通告的地址。相当于 -bind 不可用时更改 -bind 地址，可以理解为 -bind 的一个备选方案。 -bind： 绑定服务器的 ip 地址，缺省值：“0.0.0.0”，这意味着 consul 将绑定到本地机器上的所有地址，并将私有 IPv4 地址通告给集群的其余节点，如果有多个私有 IPv4 地址可用，consul 将在启动时退出并报错。consul 1.1.0 之后，可以结合 go-sockaddr template使用，例如 1$ consul agent -bind &#39;&#123;&#123; GetPrivateInterfaces | include &quot;network&quot; &quot;10.0.0.0&#x2F;8&quot; | attr &quot;address&quot; &#125;&#125;&#39; -client：客户端可访问 ip，缺省值为：“127.0.0.1”，即仅允许环回连接。 -bootstrap-expect：在一个 datacenter 中期望的 server 节点数目，consul 启动时会一直等待直到达到这个数目的server才会引导整个集群。这个参数的值在同一个 datacenter 的所有server节点上必须保持一致。 -bootstrap：用来控制一个 server 是否运行在 bootstrap 模式：当一个 server 处于 bootstrap 模式时，它可以选举自己为 leader；注意在一个 datacenter 中只能有一个 server 处于 bootstrap 模式。所以这个参数一般只能用在只有一个 server 的开发环境中，在有多个 server 的 cluster 产品环境中，不能使用这个参数，否则如果多个 server 都标记自己为 leader 那么会导致数据不一致。另外该标记不能和 -bootstrap-expect 同时指定。 服务注册1、通过 config-file 注册服务，编辑 xxx.json，然后放在 /consul/config 目录下（默认情况）,当然也可以通过 consul 命令行加载配置。 12345678910111213141516171819202122&#123; \"services\": [ &#123; \"id\": \"hertz-demo-001\", \"name\": \"hertz-demo\", \"tags\": [ ], \"address\": \"192.168.0.103\", \"port\": 5000, \"checks\": [ &#123; \"http\": \"http://192.168.0.103:5000/ping\", \"tlsSkipVerify\": false, \"method\": \"GET\", \"interval\": \"10s\", \"timeout\": \"1s\", \"deregisterCriticalServiceAfter\": \"30s\" &#125; ] &#125; ] &#125; 2、执行 consul 命令重载配置文件 1consul reload 3、启动 web 服务，这里使用自己熟悉的语言写一个简单的服务即可，这里用的是 go http 框架 hertz: 1234567891011121314151617181920212223package mainimport ( \"context\" \"github.com/cloudwego/hertz/pkg/app\" \"github.com/cloudwego/hertz/pkg/app/server\" \"github.com/cloudwego/hertz/pkg/common/utils\" \"github.com/cloudwego/hertz/pkg/protocol/consts\" \"log\")func main() &#123; s := server.Default( server.WithHostPorts(\"192.168.0.103:5000\"), ) s.GET(\"/ping\", func(ctx context.Context, req *app.RequestContext) &#123; log.Print(req.ClientIP(), \" ping\") req.JSON(consts.StatusOK, utils.H&#123;\"ping\": \"pong\"&#125;) &#125;) s.Spin()&#125; 4、查看服务健康信息，passing 参数表示是否过滤不健康的服务 1curl http://127.0.0.1:8500/v1/health/service/hertz-demo\\?passing\\=true 5、注销服务 1curl --request PUT 127.0.0.1:8501/v1/agent/service/deregister/hertz-demo-001 6、consul ui 界面上显示如下： 注意事项1、注册服务时，check 参数 method GET 注意 GET 需要大写，否则健康检查会失败 2、服务注册的 client agent 挂了，那么 consul 会认为服务也挂了，并不会做故障转移，也不会同步原本 client agent 下的服务信息 3、服务注册需要确保网络能联通 扩展1、官方推荐的架构方式 官方建议一个集群部署 3-5 个 server agent，每个服务的服务器部署一个 client agent，如下如所示： 2、如是想要统一管理 consul agent，那可以参考另一种架构方式： 参考：https://mp.weixin.qq.com/s/ecmqqWuMho2a0xhaF1vFNAhttps://www.cnblogs.com/brady-wang/p/14440649.html","categories":[],"tags":[{"name":"consul","slug":"consul","permalink":"http://example.com/tags/consul/"},{"name":"运维","slug":"运维","permalink":"http://example.com/tags/%E8%BF%90%E7%BB%B4/"}]},{"title":"Hello World","slug":"hello-world","date":"2023-03-25T16:04:15.447Z","updated":"2023-03-25T16:04:15.447Z","comments":true,"path":"2023/03/26/hello-world/","link":"","permalink":"http://example.com/2023/03/26/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]},{"title":"mysql 单机多实例","slug":"mysql-单机多实例","date":"2022-12-16T09:26:58.000Z","updated":"2024-06-27T09:41:04.715Z","comments":true,"path":"2022/12/16/mysql-单机多实例/","link":"","permalink":"http://example.com/2022/12/16/mysql-%E5%8D%95%E6%9C%BA%E5%A4%9A%E5%AE%9E%E4%BE%8B/","excerpt":"","text":"为每个实例创建单独的配置文件及数据目录 my.cnf 配置文件如下 123456789[mysql]socket = /usr/local/mysql/instance/3306/data/mysql.sock[mysqld]basedir = /usr/local/mysqldatadir = /usr/local/mysql/instance/3306/dataport = 3306socket = /usr/local/mysql/instance/3306/data/mysql.socklog_error = /usr/local/mysql/instance/3306/data/mysql-errorpid_file = /usr/local/mysql/instance/3306/data/mysql.pid 初始化 data 目录 12345678910mysqld --initialize --basedir=/usr/local/mysql --datadir=/usr/local/mysql/instance/3308/data2022-12-14T15:14:26.003364Z 0 [Warning] TIMESTAMP with implicit DEFAULT value is deprecated. Please use --explicit_defaults_for_timestamp server option (see documentation for more details).2022-12-14T15:14:26.005452Z 0 [Warning] Setting lower_case_table_names=2 because file system for /usr/local/mysql/instance/3308/data/ is case insensitive2022-12-14T15:14:26.129712Z 0 [Warning] InnoDB: New log files created, LSN=457902022-12-14T15:14:26.151110Z 0 [Warning] InnoDB: Creating foreign key constraint system tables.2022-12-14T15:14:26.218698Z 0 [Warning] No existing UUID has been found, so we assume that this is the first time that this server has been started. Generating a new UUID: ff66d330-7bc1-11ed-9e9b-119ad045e8ba.2022-12-14T15:14:26.249279Z 0 [Warning] Gtid table is not ready to be used. Table 'mysql.gtid_executed' cannot be opened.2022-12-14T15:14:26.884182Z 0 [Warning] CA certificate ca.pem is self signed.2022-12-14T15:14:26.977637Z 1 [Note] A temporary password is generated for root@localhost: phbSZ0nOis=e 启动 mysql 服务端 1mysqld --defaults-file=/usr/local/mysql/instance/3308/my.cnf &amp; mysql 客户端中更改用户密码，初始密码在初始化时能获取（忘记了可以在网上搜搜跳过认证流程） 1mysql -u root -p -S /usr/local/mysql/instance/3308/data/mysql.sock 将启动命令存到 123456789alias mysqld3306=\"mysqld --defaults-file=/usr/local/mysql/instance/3306/my.cnf &amp;\"alias mysqld3307=\"mysqld --defaults-file=/usr/local/mysql/instance/3307/my.cnf &amp;\"alias mysqld3308=\"mysqld --defaults-file=/usr/local/mysql/instance/3308/my.cnf &amp;\"alias mysql3306=\"mysql -u root -p -S /usr/local/mysql/instance/3306/data/mysql.sock\"alias mysql3307=\"mysql -u root -p -S /usr/local/mysql/instance/3307/data/mysql.sock\"alias mysql3308=\"mysql -u root -p -S /usr/local/mysql/instance/3308/data/mysql.sock\"alias mysqlkill3306=\"mysqladmin -uroot -p -S /usr/local/mysql/instance/3306/data/mysql.sock shutdown\"alias mysqlkill3307=\"mysqladmin -uroot -p -S /usr/local/mysql/instance/3307/data/mysql.sock shutdown\"alias mysqlkill3308=\"mysqladmin -uroot -p -S /usr/local/mysql/instance/3308/data/mysql.sock shutdown\"","categories":[],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://example.com/tags/mysql/"}]}],"categories":[{"name":"redisson","slug":"redisson","permalink":"http://example.com/categories/redisson/"}],"tags":[{"name":"apollo","slug":"apollo","permalink":"http://example.com/tags/apollo/"},{"name":"spring","slug":"spring","permalink":"http://example.com/tags/spring/"},{"name":"nacos","slug":"nacos","permalink":"http://example.com/tags/nacos/"},{"name":"ES","slug":"ES","permalink":"http://example.com/tags/ES/"},{"name":"分布式事务","slug":"分布式事务","permalink":"http://example.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/"},{"name":"jvm","slug":"jvm","permalink":"http://example.com/tags/jvm/"},{"name":"kafka","slug":"kafka","permalink":"http://example.com/tags/kafka/"},{"name":"java","slug":"java","permalink":"http://example.com/tags/java/"},{"name":"计算机网络","slug":"计算机网络","permalink":"http://example.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"},{"name":"运维","slug":"运维","permalink":"http://example.com/tags/%E8%BF%90%E7%BB%B4/"},{"name":"k8s","slug":"k8s","permalink":"http://example.com/tags/k8s/"},{"name":"redisson","slug":"redisson","permalink":"http://example.com/tags/redisson/"},{"name":"框架","slug":"框架","permalink":"http://example.com/tags/%E6%A1%86%E6%9E%B6/"},{"name":"consul","slug":"consul","permalink":"http://example.com/tags/consul/"},{"name":"mysql","slug":"mysql","permalink":"http://example.com/tags/mysql/"}]}